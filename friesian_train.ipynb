{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "friesian_train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO0+1f49uTmLWQmd2E0Hh+k",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hkvision/bigdl-demo/blob/main/friesian_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Environment Preparation"
      ],
      "metadata": {
        "id": "KeSWNiiV9p9u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3toUa5UfCc0u",
        "outputId": "5cdc50bc-d332-4d8a-a9ec-8c97576189fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java to provide /usr/bin/java (java) in manual mode\n",
            "openjdk version \"1.8.0_342\"\n",
            "OpenJDK Runtime Environment (build 1.8.0_342-8u342-b07-0ubuntu1~18.04-b07)\n",
            "OpenJDK 64-Bit Server VM (build 25.342-b07, mixed mode)\n"
          ]
        }
      ],
      "source": [
        "# Install jdk8\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "import os\n",
        "# Set environment variable JAVA_HOME.\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "!update-alternatives --set java /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java\n",
        "!java -version"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --pre --upgrade bigdl-friesian-spark3[train]\n",
        "!pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fg35k0L_G6Pu",
        "outputId": "1bee5302-e813-417e-dc60-75995697c4d3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting bigdl-friesian-spark3[train]\n",
            "  Downloading bigdl_friesian_spark3-2.1.0b20220820-py3-none-manylinux1_x86_64.whl (114 kB)\n",
            "\u001b[K     |████████████████████████████████| 114 kB 6.8 MB/s \n",
            "\u001b[?25hCollecting bigdl-orca-spark3==2.1.0b20220820\n",
            "  Downloading bigdl_orca_spark3-2.1.0b20220820-py3-none-manylinux1_x86_64.whl (21.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 21.8 MB 1.6 MB/s \n",
            "\u001b[?25hCollecting bigdl-math==0.14.0.dev1\n",
            "  Downloading bigdl_math-0.14.0.dev1-py3-none-manylinux2010_x86_64.whl (35.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 35.4 MB 490 kB/s \n",
            "\u001b[?25hCollecting bigdl-dllib-spark3==2.1.0b20220820\n",
            "  Downloading bigdl_dllib_spark3-2.1.0b20220820-py3-none-manylinux1_x86_64.whl (50.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 50.0 MB 45 kB/s \n",
            "\u001b[?25hRequirement already satisfied: pyzmq in /usr/local/lib/python3.7/dist-packages (from bigdl-orca-spark3==2.1.0b20220820->bigdl-friesian-spark3[train]) (23.2.1)\n",
            "Collecting bigdl-tf==0.14.0.dev1\n",
            "  Downloading bigdl_tf-0.14.0.dev1-py3-none-manylinux2010_x86_64.whl (71.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 71.0 MB 371 bytes/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from bigdl-orca-spark3==2.1.0b20220820->bigdl-friesian-spark3[train]) (3.8.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from bigdl-orca-spark3==2.1.0b20220820->bigdl-friesian-spark3[train]) (21.3)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.7/dist-packages (from bigdl-dllib-spark3==2.1.0b20220820->bigdl-orca-spark3==2.1.0b20220820->bigdl-friesian-spark3[train]) (1.21.6)\n",
            "Collecting bigdl-core==2.1.0b20220820\n",
            "  Downloading bigdl_core-2.1.0b20220820-py3-none-manylinux2010_x86_64.whl (48.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 48.2 MB 1.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from bigdl-dllib-spark3==2.1.0b20220820->bigdl-orca-spark3==2.1.0b20220820->bigdl-friesian-spark3[train]) (1.15.0)\n",
            "Collecting conda-pack==0.3.1\n",
            "  Downloading conda_pack-0.3.1-py2.py3-none-any.whl (27 kB)\n",
            "Collecting pyspark==3.1.2\n",
            "  Downloading pyspark-3.1.2.tar.gz (212.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 212.4 MB 65 kB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from conda-pack==0.3.1->bigdl-dllib-spark3==2.1.0b20220820->bigdl-orca-spark3==2.1.0b20220820->bigdl-friesian-spark3[train]) (57.4.0)\n",
            "Collecting py4j==0.10.9\n",
            "  Downloading py4j-0.10.9-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 45.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: aiohttp==3.8.1 in /usr/local/lib/python3.7/dist-packages (from bigdl-orca-spark3==2.1.0b20220820->bigdl-friesian-spark3[train]) (3.8.1)\n",
            "Collecting setproctitle\n",
            "  Downloading setproctitle-1.3.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Collecting aioredis==1.3.1\n",
            "  Downloading aioredis-1.3.1-py3-none-any.whl (65 kB)\n",
            "\u001b[K     |████████████████████████████████| 65 kB 4.9 MB/s \n",
            "\u001b[?25hCollecting hiredis==2.0.0\n",
            "  Downloading hiredis-2.0.0-cp37-cp37m-manylinux2010_x86_64.whl (85 kB)\n",
            "\u001b[K     |████████████████████████████████| 85 kB 3.8 MB/s \n",
            "\u001b[?25hCollecting async-timeout==4.0.1\n",
            "  Downloading async_timeout-4.0.1-py3-none-any.whl (5.7 kB)\n",
            "Collecting ray[default]==1.9.2\n",
            "  Downloading ray-1.9.2-cp37-cp37m-manylinux2014_x86_64.whl (57.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 57.6 MB 1.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from bigdl-orca-spark3==2.1.0b20220820->bigdl-friesian-spark3[train]) (5.4.8)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.8.1->bigdl-orca-spark3==2.1.0b20220820->bigdl-friesian-spark3[train]) (2.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.8.1->bigdl-orca-spark3==2.1.0b20220820->bigdl-friesian-spark3[train]) (1.8.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.8.1->bigdl-orca-spark3==2.1.0b20220820->bigdl-friesian-spark3[train]) (6.0.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.8.1->bigdl-orca-spark3==2.1.0b20220820->bigdl-friesian-spark3[train]) (1.3.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.8.1->bigdl-orca-spark3==2.1.0b20220820->bigdl-friesian-spark3[train]) (1.2.0)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.8.1->bigdl-orca-spark3==2.1.0b20220820->bigdl-friesian-spark3[train]) (0.13.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.8.1->bigdl-orca-spark3==2.1.0b20220820->bigdl-friesian-spark3[train]) (22.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.8.1->bigdl-orca-spark3==2.1.0b20220820->bigdl-friesian-spark3[train]) (4.1.1)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray[default]==1.9.2->bigdl-orca-spark3==2.1.0b20220820->bigdl-friesian-spark3[train]) (7.1.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from ray[default]==1.9.2->bigdl-orca-spark3==2.1.0b20220820->bigdl-friesian-spark3[train]) (6.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray[default]==1.9.2->bigdl-orca-spark3==2.1.0b20220820->bigdl-friesian-spark3[train]) (4.3.3)\n",
            "Requirement already satisfied: grpcio>=1.28.1 in /usr/local/lib/python3.7/dist-packages (from ray[default]==1.9.2->bigdl-orca-spark3==2.1.0b20220820->bigdl-friesian-spark3[train]) (1.47.0)\n",
            "Collecting redis>=3.5.0\n",
            "  Downloading redis-4.4.0rc1-py3-none-any.whl (233 kB)\n",
            "\u001b[K     |████████████████████████████████| 233 kB 73.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray[default]==1.9.2->bigdl-orca-spark3==2.1.0b20220820->bigdl-friesian-spark3[train]) (1.0.4)\n",
            "Requirement already satisfied: protobuf>=3.15.3 in /usr/local/lib/python3.7/dist-packages (from ray[default]==1.9.2->bigdl-orca-spark3==2.1.0b20220820->bigdl-friesian-spark3[train]) (3.17.3)\n",
            "Collecting colorful\n",
            "  Downloading colorful-0.6.0a1-py2.py3-none-any.whl (202 kB)\n",
            "\u001b[K     |████████████████████████████████| 202 kB 66.6 MB/s \n",
            "\u001b[?25hCollecting gpustat>=1.0.0b1\n",
            "  Downloading gpustat-1.0.0rc1.tar.gz (89 kB)\n",
            "\u001b[K     |████████████████████████████████| 89 kB 9.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from ray[default]==1.9.2->bigdl-orca-spark3==2.1.0b20220820->bigdl-friesian-spark3[train]) (2.23.0)\n",
            "Collecting opencensus\n",
            "  Downloading opencensus-0.11.0-py2.py3-none-any.whl (128 kB)\n",
            "\u001b[K     |████████████████████████████████| 128 kB 71.3 MB/s \n",
            "\u001b[?25hCollecting prometheus-client>=0.7.1\n",
            "  Downloading prometheus_client-0.14.1-py3-none-any.whl (59 kB)\n",
            "\u001b[K     |████████████████████████████████| 59 kB 8.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: smart-open in /usr/local/lib/python3.7/dist-packages (from ray[default]==1.9.2->bigdl-orca-spark3==2.1.0b20220820->bigdl-friesian-spark3[train]) (5.2.1)\n",
            "Collecting aiohttp-cors\n",
            "  Downloading aiohttp_cors-0.7.0-py3-none-any.whl (27 kB)\n",
            "Collecting py-spy>=0.2.0\n",
            "  Downloading py_spy-0.4.0_dev2-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 51.1 MB/s \n",
            "\u001b[?25hCollecting nvidia-ml-py<=11.495.46,>=11.450.129\n",
            "  Downloading nvidia_ml_py-11.495.46-py3-none-any.whl (25 kB)\n",
            "Collecting psutil\n",
            "  Downloading psutil-5.9.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (281 kB)\n",
            "\u001b[K     |████████████████████████████████| 281 kB 59.7 MB/s \n",
            "\u001b[?25hCollecting blessed>=1.17.1\n",
            "  Downloading blessed-1.19.1-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 6.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wcwidth>=0.1.4 in /usr/local/lib/python3.7/dist-packages (from blessed>=1.17.1->gpustat>=1.0.0b1->ray[default]==1.9.2->bigdl-orca-spark3==2.1.0b20220820->bigdl-friesian-spark3[train]) (0.2.5)\n",
            "Collecting deprecated>=1.2.3\n",
            "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: importlib-metadata>=1.0 in /usr/local/lib/python3.7/dist-packages (from redis>=3.5.0->ray[default]==1.9.2->bigdl-orca-spark3==2.1.0b20220820->bigdl-friesian-spark3[train]) (4.12.0)\n",
            "Collecting redis>=3.5.0\n",
            "  Downloading redis-4.3.4-py3-none-any.whl (246 kB)\n",
            "\u001b[K     |████████████████████████████████| 246 kB 59.9 MB/s \n",
            "\u001b[?25h  Downloading redis-4.3.3-py3-none-any.whl (244 kB)\n",
            "\u001b[K     |████████████████████████████████| 244 kB 57.5 MB/s \n",
            "\u001b[?25h  Downloading redis-4.3.2-py3-none-any.whl (244 kB)\n",
            "\u001b[K     |████████████████████████████████| 244 kB 47.8 MB/s \n",
            "\u001b[?25h  Downloading redis-4.3.1-py3-none-any.whl (241 kB)\n",
            "\u001b[K     |████████████████████████████████| 241 kB 60.7 MB/s \n",
            "\u001b[?25h  Downloading redis-4.3.0-py3-none-any.whl (241 kB)\n",
            "\u001b[K     |████████████████████████████████| 241 kB 59.5 MB/s \n",
            "\u001b[?25h  Downloading redis-4.2.2-py3-none-any.whl (226 kB)\n",
            "\u001b[K     |████████████████████████████████| 226 kB 73.5 MB/s \n",
            "\u001b[?25h  Downloading redis-4.2.1-py3-none-any.whl (225 kB)\n",
            "\u001b[K     |████████████████████████████████| 225 kB 75.9 MB/s \n",
            "\u001b[?25h  Downloading redis-4.2.0-py3-none-any.whl (225 kB)\n",
            "\u001b[K     |████████████████████████████████| 225 kB 41.4 MB/s \n",
            "\u001b[?25h  Downloading redis-4.2.0rc3-py3-none-any.whl (224 kB)\n",
            "\u001b[K     |████████████████████████████████| 224 kB 72.2 MB/s \n",
            "\u001b[?25h  Downloading redis-4.2.0rc2-py3-none-any.whl (223 kB)\n",
            "\u001b[K     |████████████████████████████████| 223 kB 73.0 MB/s \n",
            "\u001b[?25h  Downloading redis-4.2.0rc1-py3-none-any.whl (220 kB)\n",
            "\u001b[K     |████████████████████████████████| 220 kB 62.1 MB/s \n",
            "\u001b[?25h  Downloading redis-4.1.4-py3-none-any.whl (175 kB)\n",
            "\u001b[K     |████████████████████████████████| 175 kB 55.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated>=1.2.3->redis>=3.5.0->ray[default]==1.9.2->bigdl-orca-spark3==2.1.0b20220820->bigdl-friesian-spark3[train]) (1.14.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.0->redis>=3.5.0->ray[default]==1.9.2->bigdl-orca-spark3==2.1.0b20220820->bigdl-friesian-spark3[train]) (3.8.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->bigdl-orca-spark3==2.1.0b20220820->bigdl-friesian-spark3[train]) (3.0.9)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.7/dist-packages (from yarl<2.0,>=1.0->aiohttp==3.8.1->bigdl-orca-spark3==2.1.0b20220820->bigdl-friesian-spark3[train]) (2.10)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray[default]==1.9.2->bigdl-orca-spark3==2.1.0b20220820->bigdl-friesian-spark3[train]) (0.18.1)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray[default]==1.9.2->bigdl-orca-spark3==2.1.0b20220820->bigdl-friesian-spark3[train]) (5.9.0)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from opencensus->ray[default]==1.9.2->bigdl-orca-spark3==2.1.0b20220820->bigdl-friesian-spark3[train]) (1.31.6)\n",
            "Collecting opencensus-context>=0.1.3\n",
            "  Downloading opencensus_context-0.2.dev0-py2.py3-none-any.whl (4.5 kB)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]==1.9.2->bigdl-orca-spark3==2.1.0b20220820->bigdl-friesian-spark3[train]) (2022.2.1)\n",
            "Requirement already satisfied: google-auth<2.0dev,>=1.25.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]==1.9.2->bigdl-orca-spark3==2.1.0b20220820->bigdl-friesian-spark3[train]) (1.35.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]==1.9.2->bigdl-orca-spark3==2.1.0b20220820->bigdl-friesian-spark3[train]) (1.56.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.25.0->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]==1.9.2->bigdl-orca-spark3==2.1.0b20220820->bigdl-friesian-spark3[train]) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.25.0->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]==1.9.2->bigdl-orca-spark3==2.1.0b20220820->bigdl-friesian-spark3[train]) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.25.0->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]==1.9.2->bigdl-orca-spark3==2.1.0b20220820->bigdl-friesian-spark3[train]) (4.2.4)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.25.0->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]==1.9.2->bigdl-orca-spark3==2.1.0b20220820->bigdl-friesian-spark3[train]) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->ray[default]==1.9.2->bigdl-orca-spark3==2.1.0b20220820->bigdl-friesian-spark3[train]) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->ray[default]==1.9.2->bigdl-orca-spark3==2.1.0b20220820->bigdl-friesian-spark3[train]) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->ray[default]==1.9.2->bigdl-orca-spark3==2.1.0b20220820->bigdl-friesian-spark3[train]) (2022.6.15)\n",
            "Building wheels for collected packages: pyspark, gpustat\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.1.2-py2.py3-none-any.whl size=212880769 sha256=6dcdf001706a3c3a0b89dc686e970aa7f599e18fbbf2cb9ca9773cc0009a0fd4\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/0a/c1/9561f6fecb759579a7d863dcd846daaa95f598744e71b02c77\n",
            "  Building wheel for gpustat (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gpustat: filename=gpustat-1.0.0rc1-py3-none-any.whl size=18872 sha256=d075b313b351fa3e925f29885e93e5defa13d4056429b319b48cb3c5c62b99bb\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/85/03/7f87ed3a11307c5ad083829b59731788971a8411c265984409\n",
            "Successfully built pyspark gpustat\n",
            "Installing collected packages: py4j, deprecated, async-timeout, redis, pyspark, psutil, opencensus-context, nvidia-ml-py, hiredis, conda-pack, blessed, bigdl-core, ray, py-spy, prometheus-client, opencensus, gpustat, colorful, bigdl-tf, bigdl-math, bigdl-dllib-spark3, aioredis, aiohttp-cors, setproctitle, bigdl-orca-spark3, bigdl-friesian-spark3\n",
            "  Attempting uninstall: async-timeout\n",
            "    Found existing installation: async-timeout 4.0.2\n",
            "    Uninstalling async-timeout-4.0.2:\n",
            "      Successfully uninstalled async-timeout-4.0.2\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 5.4.8\n",
            "    Uninstalling psutil-5.4.8:\n",
            "      Successfully uninstalled psutil-5.4.8\n",
            "Successfully installed aiohttp-cors-0.7.0 aioredis-1.3.1 async-timeout-4.0.1 bigdl-core-2.1.0b20220820 bigdl-dllib-spark3-2.1.0b20220820 bigdl-friesian-spark3-2.1.0b20220820 bigdl-math-0.14.0.dev1 bigdl-orca-spark3-2.1.0b20220820 bigdl-tf-0.14.0.dev1 blessed-1.19.1 colorful-0.6.0a1 conda-pack-0.3.1 deprecated-1.2.13 gpustat-1.0.0rc1 hiredis-2.0.0 nvidia-ml-py-11.495.46 opencensus-0.11.0 opencensus-context-0.2.dev0 prometheus-client-0.14.1 psutil-5.9.1 py-spy-0.4.0.dev2 py4j-0.10.9 pyspark-3.1.2 ray-1.9.2 redis-4.1.4 setproctitle-1.3.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "psutil"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.2+zzzcolab20220719082949)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.47.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.1.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.6)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.26.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.2.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.9)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from pyspark.sql.types import StructType, StructField, StringType, LongType, BooleanType\n",
        "from bigdl.orca import init_orca_context, stop_orca_context, OrcaContext\n",
        "from bigdl.orca.learn.tf2.estimator import Estimator\n",
        "from bigdl.friesian.feature import FeatureTable\n",
        "\n",
        "# To display terminal's stdout and stderr in the Jupyter notebook.\n",
        "OrcaContext.log_output = True\n",
        "\n",
        "sc = init_orca_context(cores=4, init_ray_on_spark=True)\n",
        "spark = OrcaContext.get_spark_session()"
      ],
      "metadata": {
        "id": "BjyLvgS0ISio",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d93b0d21-7664-4951-b5e5-3d3eef1aa7fa"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing orca context\n",
            "Current pyspark location is : /usr/local/lib/python3.7/dist-packages/pyspark/__init__.py\n",
            "Start to getOrCreate SparkContext\n",
            "pyspark_submit_args is:  --driver-class-path /usr/local/lib/python3.7/dist-packages/bigdl/share/dllib/lib/bigdl-dllib-spark_3.1.2-2.1.0-SNAPSHOT-jar-with-dependencies.jar:/usr/local/lib/python3.7/dist-packages/bigdl/share/orca/lib/bigdl-orca-spark_3.1.2-2.1.0-SNAPSHOT-jar-with-dependencies.jar:/usr/local/lib/python3.7/dist-packages/bigdl/share/friesian/lib/bigdl-friesian-spark_3.1.2-2.1.0-SNAPSHOT-jar-with-dependencies.jar:/usr/local/lib/python3.7/dist-packages/bigdl/share/core/lib/all-2.1.0-20220728.053003-14.jar pyspark-shell \n",
            "Successfully got a SparkContext\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-08-22 10:45:40,601\tINFO services.py:1340 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://172.28.0.2:8265\u001b[39m\u001b[22m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'node_ip_address': '172.28.0.2', 'raylet_ip_address': '172.28.0.2', 'redis_address': '172.28.0.2:6379', 'object_store_address': '/tmp/ray/session_2022-08-22_10-45-33_584634_65/sockets/plasma_store', 'raylet_socket_name': '/tmp/ray/session_2022-08-22_10-45-33_584634_65/sockets/raylet', 'webui_url': '172.28.0.2:8265', 'session_dir': '/tmp/ray/session_2022-08-22_10-45-33_584634_65', 'metrics_export_port': 65253, 'node_id': 'fa92bbaab2e9608e618f2a0f99854e6c5c0bad172155928e470e9b4b'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate random data for 2021 Twitter Recsys Challenge"
      ],
      "metadata": {
        "id": "Lt3c07B993VV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "id_list = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\",\n",
        "           \"9\", \"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\",\n",
        "           \"I\", \"J\", \"K\", \"L\", \"M\", \"N\", \"O\", \"P\", \"Q\",\n",
        "           \"R\", \"S\", \"T\", \"U\", \"V\", \"W\", \"X\", \"Y\", \"Z\"]\n",
        "media_list = [\"Photo\", \"Video\", \"GIF\"]\n",
        "tweet_list = [\"Retweet\", \"Quote\", \"TopLevel\"]\n",
        "language_list = [\"\".join(random.choices(id_list, k=32)) for _ in range(65)]"
      ],
      "metadata": {
        "id": "pEGXGI1xivRn"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "schema = StructType(\n",
        "    [StructField(\"text_tokens\", StringType(), True),\n",
        "     StructField(\"hashtags\", StringType(), True),\n",
        "     StructField(\"tweet_id\", StringType(), True),\n",
        "     StructField(\"present_media\", StringType(), True),\n",
        "     StructField(\"present_links\", StringType(), True),\n",
        "     StructField(\"present_domains\", StringType(), True),\n",
        "     StructField(\"tweet_type\", StringType(), True),\n",
        "     StructField(\"language\", StringType(), True),\n",
        "     StructField(\"tweet_timestamp\", LongType(), True),\n",
        "     StructField(\"engaged_with_user_id\", StringType(), True),\n",
        "     StructField(\"engaged_with_user_follower_count\", LongType(), True),\n",
        "     StructField(\"engaged_with_user_following_count\", LongType(), True),\n",
        "     StructField(\"engaged_with_user_is_verified\", BooleanType(), True),\n",
        "     StructField(\"engaged_with_user_account_creation\", LongType(), True),\n",
        "     StructField(\"enaging_user_id\", StringType(), True),\n",
        "     StructField(\"enaging_user_follower_count\", LongType(), True),\n",
        "     StructField(\"enaging_user_following_count\", LongType(), True),\n",
        "     StructField(\"enaging_user_is_verified\", BooleanType(), True),\n",
        "     StructField(\"enaging_user_account_creation\", LongType(), True),\n",
        "     StructField(\"engagee_follows_engager\", StringType(), True),\n",
        "     StructField(\"reply_timestamp\", LongType(), True),\n",
        "     StructField(\"retweet_timestamp\", LongType(), True),\n",
        "     StructField(\"retweet_with_comment_timestamp\", LongType(), True),\n",
        "     StructField(\"like_timestamp\", LongType(), True)])"
      ],
      "metadata": {
        "id": "lhQZsu6BixGw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_record(random_seed):\n",
        "    random.seed(random_seed)\n",
        "    text_tokens = \"\\t\".join([str(random.randint(1, 1000))\n",
        "                            for i in range(random.randint(1, 10))])\n",
        "    hashtags = \"\\t\".join([\"\".join(random.choices(id_list, k=32))\n",
        "                          for i in range(random.randint(0, 50))])\n",
        "    tweet_id = \"\".join(random.choices(id_list, k=32))\n",
        "    present_media = \"\\t\".join(random.choices(\n",
        "        media_list, k=random.randint(0, 9)))\n",
        "    present_links = \"\\t\".join([\"\".join(random.choices(id_list, k=32))\n",
        "                               for i in range(random.randint(0, 10))])\n",
        "    present_domains = \"\\t\".join([\"\".join(random.choices(id_list, k=32))\n",
        "                                for i in range(random.randint(0, 10))])\n",
        "    tweet_type = random.choices(tweet_list)[0]\n",
        "    language = random.choices(language_list)[0]\n",
        "    tweet_timestamp = random.randint(946656000, 1609430400)\n",
        "    engaged_with_user_id = \"\".join(random.choices(id_list, k=32))\n",
        "    engaged_with_user_follower_count = random.randint(0, 10000)\n",
        "    engaged_with_user_following_count = random.randint(0, 10000)\n",
        "    engaged_with_user_is_verified = bool(random.getrandbits(1))\n",
        "    engaged_with_user_account_creation = random.randint(946656000, 1609430400)\n",
        "    enaging_user_id = \"\".join(random.choices(id_list, k=32))\n",
        "    enaging_user_follower_count = random.randint(0, 10000)\n",
        "    enaging_user_following_count = random.randint(0, 10000)\n",
        "    enaging_user_is_verified = bool(random.getrandbits(1))\n",
        "    enaging_user_account_creation = random.randint(946656000, 1609430400)\n",
        "    engagee_follows_engager = bool(random.getrandbits(1))\n",
        "    reply = bool(random.getrandbits(1))\n",
        "    reply_timestamp = random.randint(946656000, 1609430400) if reply else None\n",
        "    retweet = bool(random.getrandbits(1))\n",
        "    retweet_timestamp = random.randint(\n",
        "        946656000, 1609430400) if retweet else None\n",
        "    comment = bool(random.getrandbits(1))\n",
        "    retweet_with_comment_timestamp = random.randint(\n",
        "        946656000, 1609430400) if comment else None\n",
        "    like = bool(random.getrandbits(1))\n",
        "    like_timestamp = random.randint(946656000, 1609430400) if like else None\n",
        "    return (text_tokens, hashtags, tweet_id, present_media, present_links, present_domains,\n",
        "            tweet_type, language, tweet_timestamp, engaged_with_user_id,\n",
        "            engaged_with_user_follower_count, engaged_with_user_following_count,\n",
        "            engaged_with_user_is_verified, engaged_with_user_account_creation,\n",
        "            enaging_user_id, enaging_user_follower_count, enaging_user_following_count,\n",
        "            enaging_user_is_verified, enaging_user_account_creation,\n",
        "            engagee_follows_engager, reply_timestamp, retweet_timestamp,\n",
        "            retweet_with_comment_timestamp, like_timestamp)"
      ],
      "metadata": {
        "id": "NXcjHj61jDr-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rdd = sc.parallelize(range(50000))\n",
        "dummy_data_rdd = rdd.map(generate_record)\n",
        "df = FeatureTable(spark.createDataFrame(dummy_data_rdd, schema))"
      ],
      "metadata": {
        "id": "00ak8wmqqaay"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_tbl, valid_tbl = df.random_split([0.8, 0.2])\n",
        "\n",
        "train_size = train_tbl.size()\n",
        "valid_size = valid_tbl.size()\n",
        "print(\"Total number of train records: {}\".format(train_size))\n",
        "print(\"Total number of validation records: {}\".format(valid_size))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tO9IjWwJr-WP",
        "outputId": "23ed2d5f-d7a1-45eb-c8da-f9d868421ebc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of train records: 40084\n",
            "Total number of validation records: 9916\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Engineering"
      ],
      "metadata": {
        "id": "zu6OkQrN97gU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bool_cols = [\n",
        "    'engaged_with_user_is_verified',\n",
        "    'enaging_user_is_verified'\n",
        "]\n",
        "\n",
        "count_cols = [\n",
        "    'engaged_with_user_follower_count',\n",
        "    'engaged_with_user_following_count',\n",
        "    'enaging_user_follower_count',\n",
        "    'enaging_user_following_count'\n",
        "]\n",
        "\n",
        "cat_cols = [\n",
        "    'present_media',\n",
        "    'tweet_type',\n",
        "    'language'\n",
        "]"
      ],
      "metadata": {
        "id": "gICYuvr8uv-Y"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "media_map = {\n",
        "    '': 0,\n",
        "    'GIF': 1,\n",
        "    'GIF_GIF': 2,\n",
        "    'GIF_Photo': 3,\n",
        "    'GIF_Video': 4,\n",
        "    'Photo': 5,\n",
        "    'Photo_GIF': 6,\n",
        "    'Photo_Photo': 7,\n",
        "    'Photo_Video': 8,\n",
        "    'Video': 9,\n",
        "    'Video_GIF': 10,\n",
        "    'Video_Photo': 11,\n",
        "    'Video_Video': 12\n",
        "}\n",
        "\n",
        "type_map = {\n",
        "    'Quote': 0,\n",
        "    'Retweet': 1,\n",
        "    'TopLevel': 2,\n",
        "}"
      ],
      "metadata": {
        "id": "RkHadUUPuzeA"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(tbl):\n",
        "    tbl = tbl.fillna(\"\", \"present_media\")\n",
        "    tbl = tbl.cast(bool_cols + count_cols, \"int\")  # cast bool and long to int\n",
        "    tbl = tbl.cut_bins(columns=count_cols,\n",
        "                       bins=[1, 1e2, 1e3, 1e4, 1e5, 1e6, 1e7],\n",
        "                       out_cols=count_cols)\n",
        "    process_media = lambda x: '_'.join(x.split('\\t')[:2])\n",
        "    tbl = tbl.apply(\"present_media\", \"present_media\", process_media, \"string\")\n",
        "    tbl = tbl.encode_string(\"present_media\", media_map)\n",
        "    tbl = tbl.encode_string(\"tweet_type\", type_map)\n",
        "\n",
        "    return tbl\n",
        "\n",
        "\n",
        "train_tbl = preprocess(train_tbl)\n",
        "valid_tbl = preprocess(valid_tbl)"
      ],
      "metadata": {
        "id": "yt5pEiR5u3ip"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_tbl, language_idx = train_tbl.category_encode(\"language\")\n",
        "valid_tbl = valid_tbl.encode_string(\"language\", language_idx)\n",
        "valid_tbl = valid_tbl.fillna(0, \"language\")\n",
        "\n",
        "print(\"The number of languages: {}\".format(language_idx.size()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UIm7OGcOu5EK",
        "outputId": "704b081b-1fe7-4c27-f942-58fca998113d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-08-22 10:47:25,639\tWARNING worker.py:1245 -- (ip=172.28.0.2) The agent on node 3ae29b84691c failed to be restarted 5 times. There are 3 possible problems if you see this error.\n",
            "  1. The dashboard might not display correct information on this node.\n",
            "  2. Metrics on this node won't be reported.\n",
            "  3. runtime_env APIs won't work.\n",
            "Check out the `dashboard_agent.log` to see the detailed failure messages.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of languages: 65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_features(tbl):\n",
        "    cross_cols = [['present_media', 'language']]\n",
        "    cross_dims = [600]\n",
        "    tbl = tbl.cross_columns(cross_cols, cross_dims)  # The resulting cross column will have name \"present_media_language\"\n",
        "\n",
        "    count_func = lambda x: str(x).count('\\t') + 1 if x else 0\n",
        "    tbl = tbl.apply(\"hashtags\", \"len_hashtags\", count_func, \"int\") \\\n",
        "        .apply(\"present_domains\", \"len_domains\", count_func, \"int\") \\\n",
        "        .apply(\"present_links\", \"len_links\", count_func, \"int\")\n",
        "    return tbl\n",
        "\n",
        "\n",
        "train_tbl = generate_features(train_tbl)\n",
        "valid_tbl = generate_features(valid_tbl)"
      ],
      "metadata": {
        "id": "LMtzBZ5lvDtD"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len_cols = ['len_hashtags',\n",
        "            'len_domains',\n",
        "            'len_links']\n",
        "\n",
        "train_tbl, min_max_dict = train_tbl.min_max_scale(len_cols)\n",
        "valid_tbl = valid_tbl.transform_min_max_scale(len_cols, min_max_dict)"
      ],
      "metadata": {
        "id": "erSwEMs5vNpY"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "timestamp_cols = [\n",
        "    'reply_timestamp',\n",
        "    'retweet_timestamp',\n",
        "    'retweet_with_comment_timestamp',\n",
        "    'like_timestamp'\n",
        "]"
      ],
      "metadata": {
        "id": "KXJAXemIvPRo"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transform_label(tbl):\n",
        "    tbl = tbl.cast(timestamp_cols, \"int\")\n",
        "    tbl = tbl.fillna(0, timestamp_cols)\n",
        "    gen_label = lambda x: 1 if max(x) > 0 else 0\n",
        "    tbl = tbl.apply(in_col=timestamp_cols, out_col=\"label\", func=gen_label, dtype=\"int\")\n",
        "    return tbl\n",
        "\n",
        "\n",
        "train_tbl = transform_label(train_tbl)\n",
        "valid_tbl = transform_label(valid_tbl)"
      ],
      "metadata": {
        "id": "YbKOZft2vQl0"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_tbl.select(bool_cols + cat_cols).show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFUSGTIOwAEK",
        "outputId": "d6ae8fb8-0047-4473-c9ed-a096c7447e83"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------------------+------------------------+-------------+----------+--------+\n",
            "|engaged_with_user_is_verified|enaging_user_is_verified|present_media|tweet_type|language|\n",
            "+-----------------------------+------------------------+-------------+----------+--------+\n",
            "|                            0|                       1|            6|         1|      32|\n",
            "|                            0|                       0|           11|         1|      57|\n",
            "|                            1|                       0|            3|         0|      27|\n",
            "|                            1|                       0|           12|         1|      20|\n",
            "|                            1|                       1|            8|         1|      13|\n",
            "+-----------------------------+------------------------+-------------+----------+--------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_tbl.select(count_cols).show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UOesaxxwFcJ",
        "outputId": "fb89efef-8ccc-4fbc-96a8-af236b9206f7"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------+---------------------------------+---------------------------+----------------------------+\n",
            "|engaged_with_user_follower_count|engaged_with_user_following_count|enaging_user_follower_count|enaging_user_following_count|\n",
            "+--------------------------------+---------------------------------+---------------------------+----------------------------+\n",
            "|                               3|                                3|                          2|                           3|\n",
            "|                               3|                                3|                          3|                           3|\n",
            "|                               3|                                3|                          3|                           3|\n",
            "|                               3|                                3|                          3|                           3|\n",
            "|                               3|                                3|                          3|                           2|\n",
            "+--------------------------------+---------------------------------+---------------------------+----------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_tbl.select(len_cols + [\"present_media_language\", \"label\"]).show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DspJCJWwQn5",
        "outputId": "96ebe9ad-9d2d-4581-f3f1-6738976dc87f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-----------+---------+----------------------+-----+\n",
            "|len_hashtags|len_domains|len_links|present_media_language|label|\n",
            "+------------+-----------+---------+----------------------+-----+\n",
            "|        0.36|        0.1|      0.1|                    79|    1|\n",
            "|         0.6|        0.9|      0.0|                   348|    1|\n",
            "|        0.48|        0.0|      0.3|                   328|    1|\n",
            "|        0.86|        0.7|      0.1|                   271|    1|\n",
            "|        0.68|        0.6|      1.0|                   135|    0|\n",
            "+------------+-----------+---------+----------------------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Wide & Deep Model Training"
      ],
      "metadata": {
        "id": "R3Aq5XkR9-tp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wide_cols = ['engaged_with_user_is_verified', 'enaging_user_is_verified']\n",
        "wide_dims = [1, 1]\n",
        "cross_cols = ['present_media_language']\n",
        "cross_dims = [600]\n",
        "\n",
        "embedding_cols = []\n",
        "embedding_dims = []\n",
        "\n",
        "cat_cols = ['present_media',\n",
        "            'tweet_type',\n",
        "            'language']\n",
        "cat_dims = [12, 2, 66]\n",
        "count_cols = ['engaged_with_user_follower_count',\n",
        "              'engaged_with_user_following_count',\n",
        "              'enaging_user_follower_count',\n",
        "              'enaging_user_following_count']\n",
        "count_dims = [7, 7, 7, 7]\n",
        "indicator_cols = cat_cols + count_cols\n",
        "indicator_dims = cat_dims + count_dims\n",
        "\n",
        "continuous_cols = ['len_hashtags',\n",
        "                   'len_domains',\n",
        "                   'len_links']\n",
        "\n",
        "column_info = { \"wide_base_cols\": wide_cols,\n",
        "                \"wide_base_dims\": wide_dims,\n",
        "                \"wide_cross_cols\": cross_cols,\n",
        "                \"wide_cross_dims\": cross_dims,\n",
        "                \"indicator_cols\": indicator_cols,\n",
        "                \"indicator_dims\": indicator_dims,\n",
        "                \"continuous_cols\": continuous_cols,\n",
        "                \"embed_cols\": [],\n",
        "                \"embed_in_dims\": [],\n",
        "                \"embed_out_dims\": [],\n",
        "                \"label\": \"label\"}"
      ],
      "metadata": {
        "id": "qwJPSp5ByR8t"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(column_info, hidden_units=[100, 50, 25]):\n",
        "    \"\"\"Build an estimator appropriate for the given model type.\"\"\"\n",
        "    wide_base_input_layers = []\n",
        "    wide_base_layers = []\n",
        "    for i in range(len(column_info[\"wide_base_cols\"])):\n",
        "        wide_base_input_layers.append(tf.keras.layers.Input(shape=[], dtype=\"int32\"))\n",
        "        wide_base_layers.append(tf.keras.backend.one_hot(wide_base_input_layers[i], column_info[\"wide_base_dims\"][i] + 1))\n",
        "\n",
        "    wide_cross_input_layers = []\n",
        "    wide_cross_layers = []\n",
        "    for i in range(len(column_info[\"wide_cross_cols\"])):\n",
        "        wide_cross_input_layers.append(tf.keras.layers.Input(shape=[], dtype=\"int32\"))\n",
        "        wide_cross_layers.append(tf.keras.backend.one_hot(wide_cross_input_layers[i], column_info[\"wide_cross_dims\"][i]))\n",
        "\n",
        "    indicator_input_layers = []\n",
        "    indicator_layers = []\n",
        "    for i in range(len(column_info[\"indicator_cols\"])):\n",
        "        indicator_input_layers.append(tf.keras.layers.Input(shape=[], dtype=\"int32\"))\n",
        "        indicator_layers.append(tf.keras.backend.one_hot(indicator_input_layers[i], column_info[\"indicator_dims\"][i] + 1))\n",
        "\n",
        "    embed_input_layers = []\n",
        "    embed_layers = []\n",
        "    for i in range(len(column_info[\"embed_in_dims\"])):\n",
        "        embed_input_layers.append(tf.keras.layers.Input(shape=[], dtype=\"int32\"))\n",
        "        iembed = tf.keras.layers.Embedding(column_info[\"embed_in_dims\"][i] + 1,\n",
        "                                           output_dim=column_info[\"embed_out_dims\"][i])(embed_input_layers[i])\n",
        "        flat_embed = tf.keras.layers.Flatten()(iembed)\n",
        "        embed_layers.append(flat_embed)\n",
        "\n",
        "    continuous_input_layers = []\n",
        "    continuous_layers = []\n",
        "    for i in range(len(column_info[\"continuous_cols\"])):\n",
        "        continuous_input_layers.append(tf.keras.layers.Input(shape=[]))\n",
        "        continuous_layers.append(tf.keras.layers.Reshape(target_shape=(1,))(continuous_input_layers[i]))\n",
        "\n",
        "    if len(wide_base_layers + wide_cross_layers) > 1:\n",
        "        wide_input = tf.keras.layers.concatenate(wide_base_layers + wide_cross_layers, axis=1)\n",
        "    else:\n",
        "        wide_input = (wide_base_layers + wide_cross_layers)[0]\n",
        "    wide_out = tf.keras.layers.Dense(1)(wide_input)\n",
        "    if len(indicator_layers + embed_layers + continuous_layers) > 1:\n",
        "        deep_concat = tf.keras.layers.concatenate(indicator_layers +\n",
        "                                                  embed_layers +\n",
        "                                                  continuous_layers, axis=1)\n",
        "    else:\n",
        "        deep_concat = (indicator_layers + embed_layers + continuous_layers)[0]\n",
        "    linear = deep_concat\n",
        "    for ilayer in range(0, len(hidden_units)):\n",
        "        linear_mid = tf.keras.layers.Dense(hidden_units[ilayer])(linear)\n",
        "        bn = tf.keras.layers.BatchNormalization()(linear_mid)\n",
        "        relu = tf.keras.layers.ReLU()(bn)\n",
        "        dropout = tf.keras.layers.Dropout(0.1)(relu)\n",
        "        linear = dropout\n",
        "    deep_out = tf.keras.layers.Dense(1)(linear)\n",
        "    added = tf.keras.layers.add([wide_out, deep_out])\n",
        "    out = tf.keras.layers.Activation(\"sigmoid\")(added)\n",
        "    model = tf.keras.models.Model(wide_base_input_layers +\n",
        "                                  wide_cross_input_layers +\n",
        "                                  indicator_input_layers +\n",
        "                                  embed_input_layers +\n",
        "                                  continuous_input_layers,\n",
        "                                  out)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "sXH7Ys4ZyVY4"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\n",
        "    \"lr\": 0.0001,\n",
        "    \"column_info\": column_info,\n",
        "    \"inter_op_parallelism\": 4,\n",
        "    \"intra_op_parallelism\": 24\n",
        "}\n",
        "batch_size = 2560"
      ],
      "metadata": {
        "id": "lIzRRgGgymJP"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_creator(config):\n",
        "    model = build_model(column_info=config[\"column_info\"],\n",
        "                        hidden_units=[1024, 1024])\n",
        "    optimizer = tf.keras.optimizers.Adam(config[\"lr\"])\n",
        "    model.compile(optimizer=optimizer,\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['binary_accuracy', 'binary_crossentropy', 'AUC', 'Precision', 'Recall'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "JuhASNfdy0Op"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "estimator = Estimator.from_keras(\n",
        "    model_creator=model_creator,\n",
        "    verbose=True,\n",
        "    config=config,\n",
        "    workers_per_node=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W48FAO-Qy3w8",
        "outputId": "1b858d45-c42f-4271-9fc1-71c72e0925e0"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(Worker pid=492)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bigdl/orca/learn/tf2/tf_runner.py:318: _CollectiveAllReduceStrategyExperimental.__init__ (from tensorflow.python.distribute.collective_all_reduce_strategy) is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(Worker pid=492)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(Worker pid=492)\u001b[0m use distribute.MultiWorkerMirroredStrategy instead\n",
            "\u001b[2m\u001b[36m(Worker pid=493)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bigdl/orca/learn/tf2/tf_runner.py:318: _CollectiveAllReduceStrategyExperimental.__init__ (from tensorflow.python.distribute.collective_all_reduce_strategy) is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(Worker pid=493)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(Worker pid=493)\u001b[0m use distribute.MultiWorkerMirroredStrategy instead\n",
            "\u001b[2m\u001b[36m(Worker pid=492)\u001b[0m 2022-08-22 10:49:11.167116: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "\u001b[2m\u001b[36m(Worker pid=493)\u001b[0m 2022-08-22 10:49:11.166937: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "steps_per_epoch = math.ceil(train_size / batch_size)\n",
        "epochs = 5\n",
        "val_steps = math.ceil(valid_size / batch_size)\n",
        "\n",
        "callbacks = [EarlyStopping(monitor='val_auc', mode='max', verbose=1, patience=3)]"
      ],
      "metadata": {
        "id": "v7ANrx510Z3C"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def label_cols(column_info):\n",
        "    return [column_info[\"label\"]]\n",
        "\n",
        "def feature_cols(column_info):\n",
        "    return column_info[\"wide_base_cols\"] + column_info[\"wide_cross_cols\"] +\\\n",
        "                  column_info[\"indicator_cols\"] + column_info[\"embed_cols\"] + column_info[\"continuous_cols\"]\n",
        "\n",
        "estimator.fit(data=train_tbl.df,\n",
        "              epochs=epochs,\n",
        "              batch_size=batch_size,\n",
        "              steps_per_epoch=steps_per_epoch,\n",
        "              validation_data=valid_tbl.df,\n",
        "              validation_steps=val_steps,\n",
        "              callbacks=callbacks,\n",
        "              feature_cols=feature_cols(column_info),\n",
        "              label_cols=label_cols(column_info))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJV4ml1Vy_4D",
        "outputId": "2fbfd798-8bba-4371-d626-e141defe940b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(Worker pid=492)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bigdl/orca/learn/tf2/tf_runner.py:196: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(Worker pid=492)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(Worker pid=492)\u001b[0m rename to distribute_datasets_from_function\n",
            "\u001b[2m\u001b[36m(Worker pid=493)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bigdl/orca/learn/tf2/tf_runner.py:196: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(Worker pid=493)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(Worker pid=493)\u001b[0m rename to distribute_datasets_from_function\n",
            "\u001b[2m\u001b[36m(Worker pid=492)\u001b[0m 2022-08-22 10:50:25.971111: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
            "\u001b[2m\u001b[36m(Worker pid=493)\u001b[0m 2022-08-22 10:50:25.928321: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(Worker pid=492)\u001b[0m Epoch 1/5\n",
            " 1/16 [>.............................] - ETA: 2:35 - loss: 1.4393 - binary_accuracy: 0.1410 - binary_crossentropy: 1.4393 - auc: 0.5365 - precision: 0.9434 - recall: 0.0838\n",
            " 2/16 [==>...........................] - ETA: 9s - loss: 1.4153 - binary_accuracy: 0.1357 - binary_crossentropy: 1.4153 - auc: 0.5211 - precision: 0.9350 - recall: 0.0784  \n",
            " 3/16 [====>.........................] - ETA: 9s - loss: 1.3972 - binary_accuracy: 0.1329 - binary_crossentropy: 1.3972 - auc: 0.5278 - precision: 0.9410 - recall: 0.0798\n",
            " 4/16 [======>.......................] - ETA: 8s - loss: 1.3761 - binary_accuracy: 0.1332 - binary_crossentropy: 1.3761 - auc: 0.5284 - precision: 0.9377 - recall: 0.0800\n",
            " 5/16 [========>.....................] - ETA: 7s - loss: 1.3587 - binary_accuracy: 0.1355 - binary_crossentropy: 1.3587 - auc: 0.5178 - precision: 0.9333 - recall: 0.0839\n",
            " 6/16 [==========>...................] - ETA: 6s - loss: 1.3402 - binary_accuracy: 0.1390 - binary_crossentropy: 1.3402 - auc: 0.5150 - precision: 0.9342 - recall: 0.0877\n",
            " 7/16 [============>.................] - ETA: 6s - loss: 1.3212 - binary_accuracy: 0.1421 - binary_crossentropy: 1.3212 - auc: 0.5081 - precision: 0.9321 - recall: 0.0901\n",
            " 8/16 [==============>...............] - ETA: 5s - loss: 1.3029 - binary_accuracy: 0.1441 - binary_crossentropy: 1.3029 - auc: 0.5069 - precision: 0.9319 - recall: 0.0921\n",
            " 9/16 [===============>..............] - ETA: 4s - loss: 1.2857 - binary_accuracy: 0.1463 - binary_crossentropy: 1.2857 - auc: 0.5072 - precision: 0.9321 - recall: 0.0949\n",
            "10/16 [=================>............] - ETA: 4s - loss: 1.2679 - binary_accuracy: 0.1490 - binary_crossentropy: 1.2679 - auc: 0.5081 - precision: 0.9337 - recall: 0.0981\n",
            "11/16 [===================>..........] - ETA: 3s - loss: 1.2510 - binary_accuracy: 0.1525 - binary_crossentropy: 1.2510 - auc: 0.5074 - precision: 0.9336 - recall: 0.1024\n",
            "12/16 [=====================>........] - ETA: 2s - loss: 1.2331 - binary_accuracy: 0.1583 - binary_crossentropy: 1.2331 - auc: 0.5065 - precision: 0.9348 - recall: 0.1077\n",
            "13/16 [=======================>......] - ETA: 2s - loss: 1.2163 - binary_accuracy: 0.1643 - binary_crossentropy: 1.2163 - auc: 0.5073 - precision: 0.9369 - recall: 0.1145\n",
            "14/16 [=========================>....] - ETA: 1s - loss: 1.2003 - binary_accuracy: 0.1700 - binary_crossentropy: 1.2003 - auc: 0.5085 - precision: 0.9369 - recall: 0.1214\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 1.1840 - binary_accuracy: 0.1765 - binary_crossentropy: 1.1840 - auc: 0.5074 - precision: 0.9354 - recall: 0.1287\n",
            "16/16 [==============================] - ETA: 0s - loss: 1.1683 - binary_accuracy: 0.1830 - binary_crossentropy: 1.1683 - auc: 0.5103 - precision: 0.9376 - recall: 0.1363\n",
            "16/16 [==============================] - 26s 1s/step - loss: 1.1683 - binary_accuracy: 0.1830 - binary_crossentropy: 1.1683 - auc: 0.5103 - precision: 0.9376 - recall: 0.1363 - val_loss: 0.7326 - val_binary_accuracy: 0.2560 - val_binary_crossentropy: 0.7326 - val_auc: 0.4834 - val_precision: 0.9251 - val_recall: 0.2250\n",
            "\u001b[2m\u001b[36m(Worker pid=492)\u001b[0m Epoch 2/5\n",
            " 1/16 [>.............................] - ETA: 10s - loss: 0.8958 - binary_accuracy: 0.3191 - binary_crossentropy: 0.8958 - auc: 0.5332 - precision: 0.9416 - recall: 0.2896\n",
            " 2/16 [==>...........................] - ETA: 9s - loss: 0.8844 - binary_accuracy: 0.3283 - binary_crossentropy: 0.8844 - auc: 0.5206 - precision: 0.9391 - recall: 0.2999 \n",
            " 3/16 [====>.........................] - ETA: 9s - loss: 0.8708 - binary_accuracy: 0.3414 - binary_crossentropy: 0.8708 - auc: 0.5235 - precision: 0.9440 - recall: 0.3160\n",
            " 4/16 [======>.......................] - ETA: 8s - loss: 0.8581 - binary_accuracy: 0.3560 - binary_crossentropy: 0.8581 - auc: 0.5289 - precision: 0.9454 - recall: 0.3318\n",
            " 5/16 [========>.....................] - ETA: 7s - loss: 0.8474 - binary_accuracy: 0.3679 - binary_crossentropy: 0.8474 - auc: 0.5195 - precision: 0.9410 - recall: 0.3463\n",
            " 6/16 [==========>...................] - ETA: 6s - loss: 0.8353 - binary_accuracy: 0.3804 - binary_crossentropy: 0.8353 - auc: 0.5201 - precision: 0.9409 - recall: 0.3610\n",
            " 7/16 [============>.................] - ETA: 6s - loss: 0.8241 - binary_accuracy: 0.3932 - binary_crossentropy: 0.8241 - auc: 0.5166 - precision: 0.9397 - recall: 0.3760\n",
            " 8/16 [==============>...............] - ETA: 5s - loss: 0.8132 - binary_accuracy: 0.4058 - binary_crossentropy: 0.8132 - auc: 0.5138 - precision: 0.9395 - recall: 0.3905\n",
            " 9/16 [===============>..............] - ETA: 4s - loss: 0.8021 - binary_accuracy: 0.4196 - binary_crossentropy: 0.8021 - auc: 0.5153 - precision: 0.9404 - recall: 0.4062\n",
            "10/16 [=================>............] - ETA: 4s - loss: 0.7905 - binary_accuracy: 0.4345 - binary_crossentropy: 0.7905 - auc: 0.5175 - precision: 0.9403 - recall: 0.4227\n",
            "11/16 [===================>..........] - ETA: 3s - loss: 0.7793 - binary_accuracy: 0.4498 - binary_crossentropy: 0.7793 - auc: 0.5169 - precision: 0.9402 - recall: 0.4403\n",
            "12/16 [=====================>........] - ETA: 3s - loss: 0.7686 - binary_accuracy: 0.4637 - binary_crossentropy: 0.7686 - auc: 0.5172 - precision: 0.9401 - recall: 0.4563\n",
            "13/16 [=======================>......] - ETA: 2s - loss: 0.7580 - binary_accuracy: 0.4782 - binary_crossentropy: 0.7580 - auc: 0.5186 - precision: 0.9404 - recall: 0.4729\n",
            "14/16 [=========================>....] - ETA: 1s - loss: 0.7474 - binary_accuracy: 0.4930 - binary_crossentropy: 0.7474 - auc: 0.5213 - precision: 0.9413 - recall: 0.4897\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7372 - binary_accuracy: 0.5069 - binary_crossentropy: 0.7372 - auc: 0.5208 - precision: 0.9407 - recall: 0.5058\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7270 - binary_accuracy: 0.5210 - binary_crossentropy: 0.7270 - auc: 0.5216 - precision: 0.9406 - recall: 0.5220\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(Worker pid=493)\u001b[0m 2022-08-22 10:51:06.022024: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
            "\u001b[2m\u001b[36m(Worker pid=492)\u001b[0m 2022-08-22 10:51:06.100021: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(Worker pid=492)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r16/16 [==============================] - 16s 1s/step - loss: 0.7270 - binary_accuracy: 0.5210 - binary_crossentropy: 0.7270 - auc: 0.5216 - precision: 0.9406 - recall: 0.5220 - val_loss: 0.7487 - val_binary_accuracy: 0.2007 - val_binary_crossentropy: 0.7487 - val_auc: 0.4858 - val_precision: 0.9324 - val_recall: 0.1594\n",
            "\u001b[2m\u001b[36m(Worker pid=492)\u001b[0m Epoch 3/5\n",
            " 1/16 [>.............................] - ETA: 10s - loss: 0.5680 - binary_accuracy: 0.7336 - binary_crossentropy: 0.5680 - auc: 0.4922 - precision: 0.9385 - recall: 0.7669\n",
            " 2/16 [==>...........................] - ETA: 9s - loss: 0.5579 - binary_accuracy: 0.7518 - binary_crossentropy: 0.5579 - auc: 0.5245 - precision: 0.9365 - recall: 0.7880 \n",
            " 3/16 [====>.........................] - ETA: 9s - loss: 0.5481 - binary_accuracy: 0.7647 - binary_crossentropy: 0.5481 - auc: 0.5348 - precision: 0.9395 - recall: 0.8005\n",
            " 4/16 [======>.......................] - ETA: 8s - loss: 0.5427 - binary_accuracy: 0.7718 - binary_crossentropy: 0.5427 - auc: 0.5259 - precision: 0.9380 - recall: 0.8098\n",
            " 5/16 [========>.....................] - ETA: 7s - loss: 0.5353 - binary_accuracy: 0.7829 - binary_crossentropy: 0.5353 - auc: 0.5271 - precision: 0.9392 - recall: 0.8215\n",
            " 6/16 [==========>...................] - ETA: 7s - loss: 0.5276 - binary_accuracy: 0.7918 - binary_crossentropy: 0.5276 - auc: 0.5297 - precision: 0.9390 - recall: 0.8319\n",
            " 7/16 [============>.................] - ETA: 6s - loss: 0.5206 - binary_accuracy: 0.8007 - binary_crossentropy: 0.5206 - auc: 0.5304 - precision: 0.9399 - recall: 0.8412\n",
            " 8/16 [==============>...............] - ETA: 5s - loss: 0.5135 - binary_accuracy: 0.8081 - binary_crossentropy: 0.5135 - auc: 0.5298 - precision: 0.9394 - recall: 0.8501\n",
            " 9/16 [===============>..............] - ETA: 4s - loss: 0.5075 - binary_accuracy: 0.8148 - binary_crossentropy: 0.5075 - auc: 0.5301 - precision: 0.9395 - recall: 0.8576\n",
            "10/16 [=================>............] - ETA: 4s - loss: 0.5011 - binary_accuracy: 0.8204 - binary_crossentropy: 0.5011 - auc: 0.5336 - precision: 0.9391 - recall: 0.8644\n",
            "11/16 [===================>..........] - ETA: 3s - loss: 0.4957 - binary_accuracy: 0.8251 - binary_crossentropy: 0.4957 - auc: 0.5338 - precision: 0.9379 - recall: 0.8709\n",
            "12/16 [=====================>........] - ETA: 2s - loss: 0.4908 - binary_accuracy: 0.8302 - binary_crossentropy: 0.4908 - auc: 0.5317 - precision: 0.9374 - recall: 0.8771\n",
            "13/16 [=======================>......] - ETA: 2s - loss: 0.4861 - binary_accuracy: 0.8343 - binary_crossentropy: 0.4861 - auc: 0.5308 - precision: 0.9364 - recall: 0.8827\n",
            "14/16 [=========================>....] - ETA: 1s - loss: 0.4801 - binary_accuracy: 0.8395 - binary_crossentropy: 0.4801 - auc: 0.5322 - precision: 0.9367 - recall: 0.8885\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.4754 - binary_accuracy: 0.8437 - binary_crossentropy: 0.4754 - auc: 0.5317 - precision: 0.9364 - recall: 0.8935\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4702 - binary_accuracy: 0.8478 - binary_crossentropy: 0.4702 - auc: 0.5331 - precision: 0.9366 - recall: 0.8980\n",
            "16/16 [==============================] - 12s 777ms/step - loss: 0.4702 - binary_accuracy: 0.8478 - binary_crossentropy: 0.4702 - auc: 0.5331 - precision: 0.9366 - recall: 0.8980 - val_loss: 0.7814 - val_binary_accuracy: 0.1453 - val_binary_crossentropy: 0.7814 - val_auc: 0.4855 - val_precision: 0.9261 - val_recall: 0.0965\n",
            "\u001b[2m\u001b[36m(Worker pid=492)\u001b[0m Epoch 4/5\n",
            " 1/16 [>.............................] - ETA: 10s - loss: 0.3913 - binary_accuracy: 0.9125 - binary_crossentropy: 0.3913 - auc: 0.5280 - precision: 0.9377 - recall: 0.9713\n",
            " 2/16 [==>...........................] - ETA: 9s - loss: 0.3856 - binary_accuracy: 0.9150 - binary_crossentropy: 0.3856 - auc: 0.5414 - precision: 0.9352 - recall: 0.9768 \n",
            " 3/16 [====>.........................] - ETA: 8s - loss: 0.3839 - binary_accuracy: 0.9152 - binary_crossentropy: 0.3839 - auc: 0.5426 - precision: 0.9326 - recall: 0.9799\n",
            " 4/16 [======>.......................] - ETA: 8s - loss: 0.3785 - binary_accuracy: 0.9184 - binary_crossentropy: 0.3785 - auc: 0.5453 - precision: 0.9349 - recall: 0.9810\n",
            " 5/16 [========>.....................] - ETA: 7s - loss: 0.3753 - binary_accuracy: 0.9186 - binary_crossentropy: 0.3753 - auc: 0.5476 - precision: 0.9349 - recall: 0.9813\n",
            " 6/16 [==========>...................] - ETA: 6s - loss: 0.3724 - binary_accuracy: 0.9189 - binary_crossentropy: 0.3724 - auc: 0.5458 - precision: 0.9344 - recall: 0.9822\n",
            " 7/16 [============>.................] - ETA: 6s - loss: 0.3671 - binary_accuracy: 0.9215 - binary_crossentropy: 0.3671 - auc: 0.5471 - precision: 0.9364 - recall: 0.9830\n",
            " 8/16 [==============>...............] - ETA: 6s - loss: 0.3635 - binary_accuracy: 0.9232 - binary_crossentropy: 0.3635 - auc: 0.5464 - precision: 0.9370 - recall: 0.9842\n",
            " 9/16 [===============>..............] - ETA: 6s - loss: 0.3606 - binary_accuracy: 0.9245 - binary_crossentropy: 0.3606 - auc: 0.5462 - precision: 0.9372 - recall: 0.9855\n",
            "10/16 [=================>............] - ETA: 5s - loss: 0.3580 - binary_accuracy: 0.9251 - binary_crossentropy: 0.3580 - auc: 0.5445 - precision: 0.9371 - recall: 0.9862\n",
            "11/16 [===================>..........] - ETA: 4s - loss: 0.3544 - binary_accuracy: 0.9262 - binary_crossentropy: 0.3544 - auc: 0.5458 - precision: 0.9377 - recall: 0.9869\n",
            "12/16 [=====================>........] - ETA: 3s - loss: 0.3512 - binary_accuracy: 0.9270 - binary_crossentropy: 0.3512 - auc: 0.5497 - precision: 0.9379 - recall: 0.9875\n",
            "13/16 [=======================>......] - ETA: 2s - loss: 0.3495 - binary_accuracy: 0.9270 - binary_crossentropy: 0.3495 - auc: 0.5503 - precision: 0.9373 - recall: 0.9881\n",
            "14/16 [=========================>....] - ETA: 1s - loss: 0.3464 - binary_accuracy: 0.9278 - binary_crossentropy: 0.3464 - auc: 0.5525 - precision: 0.9377 - recall: 0.9887\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.3443 - binary_accuracy: 0.9282 - binary_crossentropy: 0.3443 - auc: 0.5514 - precision: 0.9376 - recall: 0.9892\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3414 - binary_accuracy: 0.9288 - binary_crossentropy: 0.3414 - auc: 0.5551 - precision: 0.9378 - recall: 0.9896\n",
            "16/16 [==============================] - 16s 1s/step - loss: 0.3414 - binary_accuracy: 0.9288 - binary_crossentropy: 0.3414 - auc: 0.5551 - precision: 0.9378 - recall: 0.9896 - val_loss: 0.8071 - val_binary_accuracy: 0.1434 - val_binary_crossentropy: 0.8071 - val_auc: 0.4851 - val_precision: 0.9298 - val_recall: 0.0938\n",
            "\u001b[2m\u001b[36m(Worker pid=492)\u001b[0m Epoch 5/5\n",
            " 1/16 [>.............................] - ETA: 9s - loss: 0.3102 - binary_accuracy: 0.9293 - binary_crossentropy: 0.3102 - auc: 0.5503 - precision: 0.9351 - recall: 0.9933\n",
            " 2/16 [==>...........................] - ETA: 8s - loss: 0.3076 - binary_accuracy: 0.9305 - binary_crossentropy: 0.3076 - auc: 0.5755 - precision: 0.9341 - recall: 0.9958\n",
            " 3/16 [====>.........................] - ETA: 8s - loss: 0.3048 - binary_accuracy: 0.9329 - binary_crossentropy: 0.3048 - auc: 0.5663 - precision: 0.9361 - recall: 0.9964\n",
            " 4/16 [======>.......................] - ETA: 7s - loss: 0.3009 - binary_accuracy: 0.9350 - binary_crossentropy: 0.3009 - auc: 0.5679 - precision: 0.9373 - recall: 0.9973\n",
            " 5/16 [========>.....................] - ETA: 6s - loss: 0.2984 - binary_accuracy: 0.9359 - binary_crossentropy: 0.2984 - auc: 0.5640 - precision: 0.9382 - recall: 0.9974\n",
            " 6/16 [==========>...................] - ETA: 6s - loss: 0.2985 - binary_accuracy: 0.9354 - binary_crossentropy: 0.2985 - auc: 0.5577 - precision: 0.9377 - recall: 0.9974\n",
            " 7/16 [============>.................] - ETA: 5s - loss: 0.2965 - binary_accuracy: 0.9356 - binary_crossentropy: 0.2965 - auc: 0.5615 - precision: 0.9375 - recall: 0.9978\n",
            " 8/16 [==============>...............] - ETA: 4s - loss: 0.2972 - binary_accuracy: 0.9343 - binary_crossentropy: 0.2972 - auc: 0.5610 - precision: 0.9362 - recall: 0.9978\n",
            " 9/16 [===============>..............] - ETA: 4s - loss: 0.2967 - binary_accuracy: 0.9334 - binary_crossentropy: 0.2967 - auc: 0.5671 - precision: 0.9351 - recall: 0.9981\n",
            "10/16 [=================>............] - ETA: 3s - loss: 0.2955 - binary_accuracy: 0.9336 - binary_crossentropy: 0.2955 - auc: 0.5664 - precision: 0.9353 - recall: 0.9981\n",
            "11/16 [===================>..........] - ETA: 2s - loss: 0.2926 - binary_accuracy: 0.9348 - binary_crossentropy: 0.2926 - auc: 0.5663 - precision: 0.9364 - recall: 0.9982\n",
            "12/16 [=====================>........] - ETA: 2s - loss: 0.2914 - binary_accuracy: 0.9348 - binary_crossentropy: 0.2914 - auc: 0.5695 - precision: 0.9363 - recall: 0.9982\n",
            "13/16 [=======================>......] - ETA: 1s - loss: 0.2901 - binary_accuracy: 0.9349 - binary_crossentropy: 0.2901 - auc: 0.5689 - precision: 0.9364 - recall: 0.9983\n",
            "14/16 [=========================>....] - ETA: 1s - loss: 0.2887 - binary_accuracy: 0.9351 - binary_crossentropy: 0.2887 - auc: 0.5689 - precision: 0.9366 - recall: 0.9983\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.2871 - binary_accuracy: 0.9353 - binary_crossentropy: 0.2871 - auc: 0.5709 - precision: 0.9367 - recall: 0.9983\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2866 - binary_accuracy: 0.9350 - binary_crossentropy: 0.2866 - auc: 0.5717 - precision: 0.9364 - recall: 0.9984\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(Worker pid=493)\u001b[0m 2022-08-22 10:51:46.633130: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
            "\u001b[2m\u001b[36m(Worker pid=492)\u001b[0m 2022-08-22 10:51:46.677194: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(Worker pid=493)\u001b[0m Epoch 5: early stopping\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'train_loss': 0.2865560054779053,\n",
              "  'train_binary_accuracy': 0.934985339641571,\n",
              "  'train_binary_crossentropy': 0.2865560054779053,\n",
              "  'train_auc': 0.5717177391052246,\n",
              "  'train_precision': 0.9363934397697449,\n",
              "  'train_recall': 0.9983834624290466,\n",
              "  'train_val_loss': 0.8280582427978516,\n",
              "  'train_val_binary_accuracy': 0.15107421576976776,\n",
              "  'train_val_binary_crossentropy': 0.8280582427978516,\n",
              "  'train_val_auc': 0.4841712415218353,\n",
              "  'train_val_precision': 0.9310019016265869,\n",
              "  'train_val_recall': 0.10255075246095657}]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = estimator.get_model()\n",
        "tf.saved_model.save(model, \"recsys_wnd/\")\n",
        "\n",
        "stop_orca_context()"
      ],
      "metadata": {
        "id": "9vbE___M03UJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "655b6a6a-3649-4317-9a1d-e2260bd76e81"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(Worker pid=492)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r16/16 [==============================] - 11s 699ms/step - loss: 0.2866 - binary_accuracy: 0.9350 - binary_crossentropy: 0.2866 - auc: 0.5717 - precision: 0.9364 - recall: 0.9984 - val_loss: 0.8281 - val_binary_accuracy: 0.1511 - val_binary_crossentropy: 0.8281 - val_auc: 0.4842 - val_precision: 0.9310 - val_recall: 0.1026\n",
            "\u001b[2m\u001b[36m(Worker pid=492)\u001b[0m Epoch 5: early stopping\n",
            "Stopping orca context\n"
          ]
        }
      ]
    }
  ]
}