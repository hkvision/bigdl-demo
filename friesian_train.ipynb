{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "friesian_train.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyORdnlMNukrEerSe8cE/rMp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hkvision/bigdl-demo/blob/main/friesian_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Environment Preparation"
      ],
      "metadata": {
        "id": "KeSWNiiV9p9u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3toUa5UfCc0u",
        "outputId": "829ea9c0-72ce-4511-9c67-a921a5b409d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java to provide /usr/bin/java (java) in manual mode\n",
            "openjdk version \"1.8.0_342\"\n",
            "OpenJDK Runtime Environment (build 1.8.0_342-8u342-b07-0ubuntu1~18.04-b07)\n",
            "OpenJDK 64-Bit Server VM (build 25.342-b07, mixed mode)\n"
          ]
        }
      ],
      "source": [
        "# Install jdk8\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "import os\n",
        "# Set environment variable JAVA_HOME.\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "!update-alternatives --set java /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java\n",
        "!java -version"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --pre --upgrade bigdl-friesian-spark3[train]\n",
        "!pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fg35k0L_G6Pu",
        "outputId": "de056c2a-6350-4a78-8f7f-0308cceb99f0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting bigdl-friesian-spark3[train]\n",
            "  Downloading bigdl_friesian_spark3-2.1.0b20220820-py3-none-manylinux1_x86_64.whl (114 kB)\n",
            "\u001b[K     |████████████████████████████████| 114 kB 5.1 MB/s \n",
            "\u001b[?25hCollecting bigdl-orca-spark3==2.1.0b20220820\n",
            "  Downloading bigdl_orca_spark3-2.1.0b20220820-py3-none-manylinux1_x86_64.whl (21.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 21.8 MB 1.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from bigdl-orca-spark3==2.1.0b20220820->bigdl-friesian-spark3[train]) (21.3)\n",
            "Requirement already satisfied: pyzmq in /usr/local/lib/python3.7/dist-packages (from bigdl-orca-spark3==2.1.0b20220820->bigdl-friesian-spark3[train]) (23.2.1)\n",
            "Collecting bigdl-tf==0.14.0.dev1\n",
            "  Downloading bigdl_tf-0.14.0.dev1-py3-none-manylinux2010_x86_64.whl (71.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 71.0 MB 365 bytes/s \n",
            "\u001b[?25hCollecting bigdl-math==0.14.0.dev1\n",
            "  Downloading bigdl_math-0.14.0.dev1-py3-none-manylinux2010_x86_64.whl (35.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 35.4 MB 471 kB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from bigdl-orca-spark3==2.1.0b20220820->bigdl-friesian-spark3[train]) (3.8.0)\n",
            "Collecting bigdl-dllib-spark3==2.1.0b20220820\n",
            "  Downloading bigdl_dllib_spark3-2.1.0b20220820-py3-none-manylinux1_x86_64.whl (50.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 50.0 MB 124 kB/s \n",
            "\u001b[?25hCollecting conda-pack==0.3.1\n",
            "  Downloading conda_pack-0.3.1-py2.py3-none-any.whl (27 kB)\n",
            "Collecting pyspark==3.1.2\n",
            "  Downloading pyspark-3.1.2.tar.gz (212.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 212.4 MB 71 kB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from bigdl-dllib-spark3==2.1.0b20220820->bigdl-orca-spark3==2.1.0b20220820->bigdl-friesian-spark3[train]) (1.15.0)\n",
            "Collecting bigdl-core==2.1.0b20220820\n",
            "  Downloading bigdl_core-2.1.0b20220820-py3-none-manylinux2010_x86_64.whl (48.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 48.2 MB 43 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.7/dist-packages (from bigdl-dllib-spark3==2.1.0b20220820->bigdl-orca-spark3==2.1.0b20220820->bigdl-friesian-spark3[train]) (1.21.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from conda-pack==0.3.1->bigdl-dllib-spark3==2.1.0b20220820->bigdl-orca-spark3==2.1.0b20220820->bigdl-friesian-spark3[train]) (57.4.0)\n",
            "Collecting py4j==0.10.9\n",
            "  Downloading py4j-0.10.9-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 67.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: aiohttp==3.8.1 in /usr/local/lib/python3.7/dist-packages (from bigdl-orca-spark3==2.1.0b20220820->bigdl-friesian-spark3[train]) (3.8.1)\n",
            "Collecting setproctitle\n",
            "  Downloading setproctitle-1.3.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Collecting ray[default]==1.9.2\n",
            "  Downloading ray-1.9.2-cp37-cp37m-manylinux2014_x86_64.whl (57.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 57.6 MB 1.2 MB/s \n",
            "\u001b[?25hCollecting async-timeout==4.0.1\n",
            "  Downloading async_timeout-4.0.1-py3-none-any.whl (5.7 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from bigdl-orca-spark3==2.1.0b20220820->bigdl-friesian-spark3[train]) (5.4.8)\n",
            "Collecting aioredis==1.3.1\n",
            "  Downloading aioredis-1.3.1-py3-none-any.whl (65 kB)\n",
            "\u001b[K     |████████████████████████████████| 65 kB 3.2 MB/s \n",
            "\u001b[?25hCollecting hiredis==2.0.0\n",
            "  Downloading hiredis-2.0.0-cp37-cp37m-manylinux2010_x86_64.whl (85 kB)\n",
            "\u001b[K     |████████████████████████████████| 85 kB 3.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.8.1->bigdl-orca-spark3==2.1.0b20220820->bigdl-friesian-spark3[train]) (1.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.8.1->bigdl-orca-spark3==2.1.0b20220820->bigdl-friesian-spark3[train]) (4.1.1)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.8.1->bigdl-orca-spark3==2.1.0b20220820->bigdl-friesian-spark3[train]) (2.1.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.8.1->bigdl-orca-spark3==2.1.0b20220820->bigdl-friesian-spark3[train]) (1.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.8.1->bigdl-orca-spark3==2.1.0b20220820->bigdl-friesian-spark3[train]) (6.0.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.8.1->bigdl-orca-spark3==2.1.0b20220820->bigdl-friesian-spark3[train]) (1.3.1)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.8.1->bigdl-orca-spark3==2.1.0b20220820->bigdl-friesian-spark3[train]) (0.13.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp==3.8.1->bigdl-orca-spark3==2.1.0b20220820->bigdl-friesian-spark3[train]) (22.1.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray[default]==1.9.2->bigdl-orca-spark3==2.1.0b20220820->bigdl-friesian-spark3[train]) (7.1.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from ray[default]==1.9.2->bigdl-orca-spark3==2.1.0b20220820->bigdl-friesian-spark3[train]) (6.0)\n",
            "Requirement already satisfied: grpcio>=1.28.1 in /usr/local/lib/python3.7/dist-packages (from ray[default]==1.9.2->bigdl-orca-spark3==2.1.0b20220820->bigdl-friesian-spark3[train]) (1.47.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray[default]==1.9.2->bigdl-orca-spark3==2.1.0b20220820->bigdl-friesian-spark3[train]) (4.3.3)\n",
            "Collecting redis>=3.5.0\n",
            "  Downloading redis-4.4.0rc1-py3-none-any.whl (233 kB)\n",
            "\u001b[K     |████████████████████████████████| 233 kB 68.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.15.3 in /usr/local/lib/python3.7/dist-packages (from ray[default]==1.9.2->bigdl-orca-spark3==2.1.0b20220820->bigdl-friesian-spark3[train]) (3.17.3)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray[default]==1.9.2->bigdl-orca-spark3==2.1.0b20220820->bigdl-friesian-spark3[train]) (1.0.4)\n",
            "Collecting opencensus\n",
            "  Downloading opencensus-0.11.0-py2.py3-none-any.whl (128 kB)\n",
            "\u001b[K     |████████████████████████████████| 128 kB 69.0 MB/s \n",
            "\u001b[?25hCollecting prometheus-client>=0.7.1\n",
            "  Downloading prometheus_client-0.14.1-py3-none-any.whl (59 kB)\n",
            "\u001b[K     |████████████████████████████████| 59 kB 6.2 MB/s \n",
            "\u001b[?25hCollecting gpustat>=1.0.0b1\n",
            "  Downloading gpustat-1.0.0rc1.tar.gz (89 kB)\n",
            "\u001b[K     |████████████████████████████████| 89 kB 8.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from ray[default]==1.9.2->bigdl-orca-spark3==2.1.0b20220820->bigdl-friesian-spark3[train]) (2.23.0)\n",
            "Collecting colorful\n",
            "  Downloading colorful-0.6.0a1-py2.py3-none-any.whl (202 kB)\n",
            "\u001b[K     |████████████████████████████████| 202 kB 64.3 MB/s \n",
            "\u001b[?25hCollecting aiohttp-cors\n",
            "  Downloading aiohttp_cors-0.7.0-py3-none-any.whl (27 kB)\n",
            "Collecting py-spy>=0.2.0\n",
            "  Downloading py_spy-0.4.0_dev2-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 52.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: smart-open in /usr/local/lib/python3.7/dist-packages (from ray[default]==1.9.2->bigdl-orca-spark3==2.1.0b20220820->bigdl-friesian-spark3[train]) (5.2.1)\n",
            "Collecting nvidia-ml-py<=11.495.46,>=11.450.129\n",
            "  Downloading nvidia_ml_py-11.495.46-py3-none-any.whl (25 kB)\n",
            "Collecting psutil\n",
            "  Downloading psutil-5.9.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (281 kB)\n",
            "\u001b[K     |████████████████████████████████| 281 kB 53.6 MB/s \n",
            "\u001b[?25hCollecting blessed>=1.17.1\n",
            "  Downloading blessed-1.19.1-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 5.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wcwidth>=0.1.4 in /usr/local/lib/python3.7/dist-packages (from blessed>=1.17.1->gpustat>=1.0.0b1->ray[default]==1.9.2->bigdl-orca-spark3==2.1.0b20220820->bigdl-friesian-spark3[train]) (0.2.5)\n",
            "Collecting deprecated>=1.2.3\n",
            "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: importlib-metadata>=1.0 in /usr/local/lib/python3.7/dist-packages (from redis>=3.5.0->ray[default]==1.9.2->bigdl-orca-spark3==2.1.0b20220820->bigdl-friesian-spark3[train]) (4.12.0)\n",
            "Collecting redis>=3.5.0\n",
            "  Downloading redis-4.3.4-py3-none-any.whl (246 kB)\n",
            "\u001b[K     |████████████████████████████████| 246 kB 56.5 MB/s \n",
            "\u001b[?25h  Downloading redis-4.3.3-py3-none-any.whl (244 kB)\n",
            "\u001b[K     |████████████████████████████████| 244 kB 43.8 MB/s \n",
            "\u001b[?25h  Downloading redis-4.3.2-py3-none-any.whl (244 kB)\n",
            "\u001b[K     |████████████████████████████████| 244 kB 55.9 MB/s \n",
            "\u001b[?25h  Downloading redis-4.3.1-py3-none-any.whl (241 kB)\n",
            "\u001b[K     |████████████████████████████████| 241 kB 68.9 MB/s \n",
            "\u001b[?25h  Downloading redis-4.3.0-py3-none-any.whl (241 kB)\n",
            "\u001b[K     |████████████████████████████████| 241 kB 57.0 MB/s \n",
            "\u001b[?25h  Downloading redis-4.2.2-py3-none-any.whl (226 kB)\n",
            "\u001b[K     |████████████████████████████████| 226 kB 65.8 MB/s \n",
            "\u001b[?25h  Downloading redis-4.2.1-py3-none-any.whl (225 kB)\n",
            "\u001b[K     |████████████████████████████████| 225 kB 49.1 MB/s \n",
            "\u001b[?25h  Downloading redis-4.2.0-py3-none-any.whl (225 kB)\n",
            "\u001b[K     |████████████████████████████████| 225 kB 59.0 MB/s \n",
            "\u001b[?25h  Downloading redis-4.2.0rc3-py3-none-any.whl (224 kB)\n",
            "\u001b[K     |████████████████████████████████| 224 kB 75.2 MB/s \n",
            "\u001b[?25h  Downloading redis-4.2.0rc2-py3-none-any.whl (223 kB)\n",
            "\u001b[K     |████████████████████████████████| 223 kB 46.3 MB/s \n",
            "\u001b[?25h  Downloading redis-4.2.0rc1-py3-none-any.whl (220 kB)\n",
            "\u001b[K     |████████████████████████████████| 220 kB 56.0 MB/s \n",
            "\u001b[?25h  Downloading redis-4.1.4-py3-none-any.whl (175 kB)\n",
            "\u001b[K     |████████████████████████████████| 175 kB 55.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated>=1.2.3->redis>=3.5.0->ray[default]==1.9.2->bigdl-orca-spark3==2.1.0b20220820->bigdl-friesian-spark3[train]) (1.14.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=1.0->redis>=3.5.0->ray[default]==1.9.2->bigdl-orca-spark3==2.1.0b20220820->bigdl-friesian-spark3[train]) (3.8.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->bigdl-orca-spark3==2.1.0b20220820->bigdl-friesian-spark3[train]) (3.0.9)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.7/dist-packages (from yarl<2.0,>=1.0->aiohttp==3.8.1->bigdl-orca-spark3==2.1.0b20220820->bigdl-friesian-spark3[train]) (2.10)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray[default]==1.9.2->bigdl-orca-spark3==2.1.0b20220820->bigdl-friesian-spark3[train]) (5.9.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema->ray[default]==1.9.2->bigdl-orca-spark3==2.1.0b20220820->bigdl-friesian-spark3[train]) (0.18.1)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from opencensus->ray[default]==1.9.2->bigdl-orca-spark3==2.1.0b20220820->bigdl-friesian-spark3[train]) (1.31.6)\n",
            "Collecting opencensus-context>=0.1.3\n",
            "  Downloading opencensus_context-0.2.dev0-py2.py3-none-any.whl (4.5 kB)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]==1.9.2->bigdl-orca-spark3==2.1.0b20220820->bigdl-friesian-spark3[train]) (1.56.4)\n",
            "Requirement already satisfied: google-auth<2.0dev,>=1.25.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]==1.9.2->bigdl-orca-spark3==2.1.0b20220820->bigdl-friesian-spark3[train]) (1.35.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]==1.9.2->bigdl-orca-spark3==2.1.0b20220820->bigdl-friesian-spark3[train]) (2022.2.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.25.0->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]==1.9.2->bigdl-orca-spark3==2.1.0b20220820->bigdl-friesian-spark3[train]) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.25.0->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]==1.9.2->bigdl-orca-spark3==2.1.0b20220820->bigdl-friesian-spark3[train]) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.25.0->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]==1.9.2->bigdl-orca-spark3==2.1.0b20220820->bigdl-friesian-spark3[train]) (0.2.8)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.25.0->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default]==1.9.2->bigdl-orca-spark3==2.1.0b20220820->bigdl-friesian-spark3[train]) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->ray[default]==1.9.2->bigdl-orca-spark3==2.1.0b20220820->bigdl-friesian-spark3[train]) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->ray[default]==1.9.2->bigdl-orca-spark3==2.1.0b20220820->bigdl-friesian-spark3[train]) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->ray[default]==1.9.2->bigdl-orca-spark3==2.1.0b20220820->bigdl-friesian-spark3[train]) (1.24.3)\n",
            "Building wheels for collected packages: pyspark, gpustat\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.1.2-py2.py3-none-any.whl size=212880769 sha256=46b170e7d18ecfb48fdae9d45ce4fa3de036990996c7e97ae21042664e8c6136\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/0a/c1/9561f6fecb759579a7d863dcd846daaa95f598744e71b02c77\n",
            "  Building wheel for gpustat (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gpustat: filename=gpustat-1.0.0rc1-py3-none-any.whl size=18872 sha256=3b17775c1afcd779e8cbee4f69e2b75d6816f778da54ea5f2ab2289020b39d76\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/85/03/7f87ed3a11307c5ad083829b59731788971a8411c265984409\n",
            "Successfully built pyspark gpustat\n",
            "Installing collected packages: py4j, deprecated, async-timeout, redis, pyspark, psutil, opencensus-context, nvidia-ml-py, hiredis, conda-pack, blessed, bigdl-core, ray, py-spy, prometheus-client, opencensus, gpustat, colorful, bigdl-tf, bigdl-math, bigdl-dllib-spark3, aioredis, aiohttp-cors, setproctitle, bigdl-orca-spark3, bigdl-friesian-spark3\n",
            "  Attempting uninstall: async-timeout\n",
            "    Found existing installation: async-timeout 4.0.2\n",
            "    Uninstalling async-timeout-4.0.2:\n",
            "      Successfully uninstalled async-timeout-4.0.2\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 5.4.8\n",
            "    Uninstalling psutil-5.4.8:\n",
            "      Successfully uninstalled psutil-5.4.8\n",
            "Successfully installed aiohttp-cors-0.7.0 aioredis-1.3.1 async-timeout-4.0.1 bigdl-core-2.1.0b20220820 bigdl-dllib-spark3-2.1.0b20220820 bigdl-friesian-spark3-2.1.0b20220820 bigdl-math-0.14.0.dev1 bigdl-orca-spark3-2.1.0b20220820 bigdl-tf-0.14.0.dev1 blessed-1.19.1 colorful-0.6.0a1 conda-pack-0.3.1 deprecated-1.2.13 gpustat-1.0.0rc1 hiredis-2.0.0 nvidia-ml-py-11.495.46 opencensus-0.11.0 opencensus-context-0.2.dev0 prometheus-client-0.14.1 psutil-5.9.1 py-spy-0.4.0.dev2 py4j-0.10.9 pyspark-3.1.2 ray-1.9.2 redis-4.1.4 setproctitle-1.3.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "psutil"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.2+zzzcolab20220719082949)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.1.1)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.6)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.26.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.47.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.2.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.12.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2022.6.15)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate random data for 2021 Twitter Recsys Challenge"
      ],
      "metadata": {
        "id": "Lt3c07B993VV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from pyspark.sql.types import StructType, StructField, StringType, LongType, BooleanType\n",
        "from bigdl.orca import init_orca_context, stop_orca_context, OrcaContext\n",
        "from bigdl.friesian.feature import FeatureTable\n",
        "\n",
        "# To display terminal's stdout and stderr in the Jupyter notebook.\n",
        "OrcaContext.log_output = True\n",
        "\n",
        "sc = init_orca_context(cores=4, init_ray_on_spark=True)\n",
        "spark = OrcaContext.get_spark_session()"
      ],
      "metadata": {
        "id": "BjyLvgS0ISio"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "id_list = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\",\n",
        "           \"9\", \"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\",\n",
        "           \"I\", \"J\", \"K\", \"L\", \"M\", \"N\", \"O\", \"P\", \"Q\",\n",
        "           \"R\", \"S\", \"T\", \"U\", \"V\", \"W\", \"X\", \"Y\", \"Z\"]\n",
        "media_list = [\"Photo\", \"Video\", \"GIF\"]\n",
        "tweet_list = [\"Retweet\", \"Quote\", \"TopLevel\"]\n",
        "language_list = [\"\".join(random.choices(id_list, k=32)) for _ in range(65)]"
      ],
      "metadata": {
        "id": "pEGXGI1xivRn"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "schema = StructType(\n",
        "    [StructField(\"text_tokens\", StringType(), True),\n",
        "     StructField(\"hashtags\", StringType(), True),\n",
        "     StructField(\"tweet_id\", StringType(), True),\n",
        "     StructField(\"present_media\", StringType(), True),\n",
        "     StructField(\"present_links\", StringType(), True),\n",
        "     StructField(\"present_domains\", StringType(), True),\n",
        "     StructField(\"tweet_type\", StringType(), True),\n",
        "     StructField(\"language\", StringType(), True),\n",
        "     StructField(\"tweet_timestamp\", LongType(), True),\n",
        "     StructField(\"engaged_with_user_id\", StringType(), True),\n",
        "     StructField(\"engaged_with_user_follower_count\", LongType(), True),\n",
        "     StructField(\"engaged_with_user_following_count\", LongType(), True),\n",
        "     StructField(\"engaged_with_user_is_verified\", BooleanType(), True),\n",
        "     StructField(\"engaged_with_user_account_creation\", LongType(), True),\n",
        "     StructField(\"enaging_user_id\", StringType(), True),\n",
        "     StructField(\"enaging_user_follower_count\", LongType(), True),\n",
        "     StructField(\"enaging_user_following_count\", LongType(), True),\n",
        "     StructField(\"enaging_user_is_verified\", BooleanType(), True),\n",
        "     StructField(\"enaging_user_account_creation\", LongType(), True),\n",
        "     StructField(\"engagee_follows_engager\", StringType(), True),\n",
        "     StructField(\"reply_timestamp\", LongType(), True),\n",
        "     StructField(\"retweet_timestamp\", LongType(), True),\n",
        "     StructField(\"retweet_with_comment_timestamp\", LongType(), True),\n",
        "     StructField(\"like_timestamp\", LongType(), True)])"
      ],
      "metadata": {
        "id": "lhQZsu6BixGw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_record(random_seed):\n",
        "    random.seed(random_seed)\n",
        "    text_tokens = \"\\t\".join([str(random.randint(1, 1000))\n",
        "                            for i in range(random.randint(1, 10))])\n",
        "    hashtags = \"\\t\".join([\"\".join(random.choices(id_list, k=32))\n",
        "                          for i in range(random.randint(0, 50))])\n",
        "    tweet_id = \"\".join(random.choices(id_list, k=32))\n",
        "    present_media = \"\\t\".join(random.choices(\n",
        "        media_list, k=random.randint(0, 9)))\n",
        "    present_links = \"\\t\".join([\"\".join(random.choices(id_list, k=32))\n",
        "                               for i in range(random.randint(0, 10))])\n",
        "    present_domains = \"\\t\".join([\"\".join(random.choices(id_list, k=32))\n",
        "                                for i in range(random.randint(0, 10))])\n",
        "    tweet_type = random.choices(tweet_list)[0]\n",
        "    language = random.choices(language_list)[0]\n",
        "    tweet_timestamp = random.randint(946656000, 1609430400)\n",
        "    engaged_with_user_id = \"\".join(random.choices(id_list, k=32))\n",
        "    engaged_with_user_follower_count = random.randint(0, 10000)\n",
        "    engaged_with_user_following_count = random.randint(0, 10000)\n",
        "    engaged_with_user_is_verified = bool(random.getrandbits(1))\n",
        "    engaged_with_user_account_creation = random.randint(946656000, 1609430400)\n",
        "    enaging_user_id = \"\".join(random.choices(id_list, k=32))\n",
        "    enaging_user_follower_count = random.randint(0, 10000)\n",
        "    enaging_user_following_count = random.randint(0, 10000)\n",
        "    enaging_user_is_verified = bool(random.getrandbits(1))\n",
        "    enaging_user_account_creation = random.randint(946656000, 1609430400)\n",
        "    engagee_follows_engager = bool(random.getrandbits(1))\n",
        "    reply = bool(random.getrandbits(1))\n",
        "    reply_timestamp = random.randint(946656000, 1609430400) if reply else None\n",
        "    retweet = bool(random.getrandbits(1))\n",
        "    retweet_timestamp = random.randint(\n",
        "        946656000, 1609430400) if retweet else None\n",
        "    comment = bool(random.getrandbits(1))\n",
        "    retweet_with_comment_timestamp = random.randint(\n",
        "        946656000, 1609430400) if comment else None\n",
        "    like = bool(random.getrandbits(1))\n",
        "    like_timestamp = random.randint(946656000, 1609430400) if like else None\n",
        "    return (text_tokens, hashtags, tweet_id, present_media, present_links, present_domains,\n",
        "            tweet_type, language, tweet_timestamp, engaged_with_user_id,\n",
        "            engaged_with_user_follower_count, engaged_with_user_following_count,\n",
        "            engaged_with_user_is_verified, engaged_with_user_account_creation,\n",
        "            enaging_user_id, enaging_user_follower_count, enaging_user_following_count,\n",
        "            enaging_user_is_verified, enaging_user_account_creation,\n",
        "            engagee_follows_engager, reply_timestamp, retweet_timestamp,\n",
        "            retweet_with_comment_timestamp, like_timestamp)"
      ],
      "metadata": {
        "id": "NXcjHj61jDr-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rdd = sc.parallelize(range(50000))\n",
        "dummy_data_rdd = rdd.map(generate_record)\n",
        "df = FeatureTable(spark.createDataFrame(dummy_data_rdd, schema))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00ak8wmqqaay",
        "outputId": "e1d10383-e9e7-41d8-96d0-408028f953c5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing orca context\n",
            "Current pyspark location is : /usr/local/lib/python3.7/dist-packages/pyspark/__init__.py\n",
            "Start to getOrCreate SparkContext\n",
            "pyspark_submit_args is:  --driver-class-path /usr/local/lib/python3.7/dist-packages/bigdl/share/dllib/lib/bigdl-dllib-spark_3.1.2-2.1.0-SNAPSHOT-jar-with-dependencies.jar:/usr/local/lib/python3.7/dist-packages/bigdl/share/orca/lib/bigdl-orca-spark_3.1.2-2.1.0-SNAPSHOT-jar-with-dependencies.jar:/usr/local/lib/python3.7/dist-packages/bigdl/share/friesian/lib/bigdl-friesian-spark_3.1.2-2.1.0-SNAPSHOT-jar-with-dependencies.jar:/usr/local/lib/python3.7/dist-packages/bigdl/share/core/lib/all-2.1.0-20220728.053003-14.jar pyspark-shell \n",
            "Successfully got a SparkContext\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-08-22 09:41:38,191\tINFO services.py:1340 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://172.28.0.2:8265\u001b[39m\u001b[22m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'node_ip_address': '172.28.0.2', 'raylet_ip_address': '172.28.0.2', 'redis_address': '172.28.0.2:6379', 'object_store_address': '/tmp/ray/session_2022-08-22_09-41-33_644736_58/sockets/plasma_store', 'raylet_socket_name': '/tmp/ray/session_2022-08-22_09-41-33_644736_58/sockets/raylet', 'webui_url': '172.28.0.2:8265', 'session_dir': '/tmp/ray/session_2022-08-22_09-41-33_644736_58', 'metrics_export_port': 49215, 'node_id': '3d8cef3a50caea4b9387379adda12a6b4a9fafe3eee1dc23813a898b'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_tbl, valid_tbl = df.random_split([0.8, 0.2])\n",
        "\n",
        "train_size = train_tbl.size()\n",
        "valid_size = valid_tbl.size()\n",
        "print(\"Total number of train records: {}\".format(train_size))\n",
        "print(\"Total number of validation records: {}\".format(valid_size))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tO9IjWwJr-WP",
        "outputId": "63993b53-7961-4c0e-b860-0be36667e147"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of train records: 40099\n",
            "Total number of validation records: 9901\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Engineering"
      ],
      "metadata": {
        "id": "zu6OkQrN97gU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bool_cols = [\n",
        "    'engaged_with_user_is_verified',\n",
        "    'enaging_user_is_verified'\n",
        "]\n",
        "\n",
        "count_cols = [\n",
        "    'engaged_with_user_follower_count',\n",
        "    'engaged_with_user_following_count',\n",
        "    'enaging_user_follower_count',\n",
        "    'enaging_user_following_count'\n",
        "]\n",
        "\n",
        "cat_cols = [\n",
        "    'present_media',\n",
        "    'tweet_type',\n",
        "    'language'\n",
        "]"
      ],
      "metadata": {
        "id": "gICYuvr8uv-Y"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "media_map = {\n",
        "    '': 0,\n",
        "    'GIF': 1,\n",
        "    'GIF_GIF': 2,\n",
        "    'GIF_Photo': 3,\n",
        "    'GIF_Video': 4,\n",
        "    'Photo': 5,\n",
        "    'Photo_GIF': 6,\n",
        "    'Photo_Photo': 7,\n",
        "    'Photo_Video': 8,\n",
        "    'Video': 9,\n",
        "    'Video_GIF': 10,\n",
        "    'Video_Photo': 11,\n",
        "    'Video_Video': 12\n",
        "}\n",
        "\n",
        "type_map = {\n",
        "    'Quote': 0,\n",
        "    'Retweet': 1,\n",
        "    'TopLevel': 2,\n",
        "}"
      ],
      "metadata": {
        "id": "RkHadUUPuzeA"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(tbl):\n",
        "    tbl = tbl.fillna(\"\", \"present_media\")\n",
        "    tbl = tbl.cast(bool_cols + count_cols, \"int\")  # cast bool and long to int\n",
        "    tbl = tbl.cut_bins(columns=count_cols,\n",
        "                       bins=[1, 1e2, 1e3, 1e4, 1e5, 1e6, 1e7],\n",
        "                       out_cols=count_cols)\n",
        "    process_media = lambda x: '_'.join(x.split('\\t')[:2])\n",
        "    tbl = tbl.apply(\"present_media\", \"present_media\", process_media, \"string\")\n",
        "    tbl = tbl.encode_string(\"present_media\", media_map)\n",
        "    tbl = tbl.encode_string(\"tweet_type\", type_map)\n",
        "\n",
        "    return tbl\n",
        "\n",
        "\n",
        "train_tbl = preprocess(train_tbl)\n",
        "valid_tbl = preprocess(valid_tbl)"
      ],
      "metadata": {
        "id": "yt5pEiR5u3ip"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_tbl, language_idx = train_tbl.category_encode(\"language\")\n",
        "valid_tbl = valid_tbl.encode_string(\"language\", language_idx)\n",
        "valid_tbl = valid_tbl.fillna(0, \"language\")\n",
        "\n",
        "print(\"The number of languages: {}\".format(language_idx.size()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UIm7OGcOu5EK",
        "outputId": "04769d9a-80fd-4739-e544-fc5684e7c6e7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of languages: 65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_features(tbl):\n",
        "    cross_cols = [['present_media', 'language']]\n",
        "    cross_dims = [600]\n",
        "    tbl = tbl.cross_columns(cross_cols, cross_dims)  # The resulting cross column will have name \"present_media_language\"\n",
        "\n",
        "    count_func = lambda x: str(x).count('\\t') + 1 if x else 0\n",
        "    tbl = tbl.apply(\"hashtags\", \"len_hashtags\", count_func, \"int\") \\\n",
        "        .apply(\"present_domains\", \"len_domains\", count_func, \"int\") \\\n",
        "        .apply(\"present_links\", \"len_links\", count_func, \"int\")\n",
        "    return tbl\n",
        "\n",
        "\n",
        "train_tbl = generate_features(train_tbl)\n",
        "valid_tbl = generate_features(valid_tbl)"
      ],
      "metadata": {
        "id": "LMtzBZ5lvDtD"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len_cols = ['len_hashtags',\n",
        "            'len_domains',\n",
        "            'len_links']\n",
        "\n",
        "train_tbl, min_max_dict = train_tbl.min_max_scale(len_cols)\n",
        "valid_tbl = valid_tbl.transform_min_max_scale(len_cols, min_max_dict)"
      ],
      "metadata": {
        "id": "erSwEMs5vNpY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ccbdb51-47bc-403a-d0aa-3669f9499619"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-08-22 09:43:30,627\tWARNING worker.py:1245 -- (ip=172.28.0.2) The agent on node a36a8ab7233c failed to be restarted 5 times. There are 3 possible problems if you see this error.\n",
            "  1. The dashboard might not display correct information on this node.\n",
            "  2. Metrics on this node won't be reported.\n",
            "  3. runtime_env APIs won't work.\n",
            "Check out the `dashboard_agent.log` to see the detailed failure messages.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "timestamp_cols = [\n",
        "    'reply_timestamp',\n",
        "    'retweet_timestamp',\n",
        "    'retweet_with_comment_timestamp',\n",
        "    'like_timestamp'\n",
        "]"
      ],
      "metadata": {
        "id": "KXJAXemIvPRo"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transform_label(tbl):\n",
        "    tbl = tbl.cast(timestamp_cols, \"int\")\n",
        "    tbl = tbl.fillna(0, timestamp_cols)\n",
        "    gen_label = lambda x: 1 if max(x) > 0 else 0\n",
        "    tbl = tbl.apply(in_col=timestamp_cols, out_col=\"label\", func=gen_label, dtype=\"int\")\n",
        "    return tbl\n",
        "\n",
        "\n",
        "train_tbl = transform_label(train_tbl)\n",
        "valid_tbl = transform_label(valid_tbl)"
      ],
      "metadata": {
        "id": "YbKOZft2vQl0"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_tbl.select(bool_cols + cat_cols).show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFUSGTIOwAEK",
        "outputId": "e5b7ff9c-196c-4b2d-cdfb-54f40494a599"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------------------+------------------------+-------------+----------+--------+\n",
            "|engaged_with_user_is_verified|enaging_user_is_verified|present_media|tweet_type|language|\n",
            "+-----------------------------+------------------------+-------------+----------+--------+\n",
            "|                            0|                       1|           12|         1|       4|\n",
            "|                            1|                       1|            8|         1|      59|\n",
            "|                            1|                       0|            6|         0|      15|\n",
            "|                            1|                       0|            3|         2|      36|\n",
            "|                            0|                       1|            2|         2|      44|\n",
            "+-----------------------------+------------------------+-------------+----------+--------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_tbl.select(count_cols).show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_UOesaxxwFcJ",
        "outputId": "81ee7436-eeb5-43d8-d99c-1675f3437af0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------------+---------------------------------+---------------------------+----------------------------+\n",
            "|engaged_with_user_follower_count|engaged_with_user_following_count|enaging_user_follower_count|enaging_user_following_count|\n",
            "+--------------------------------+---------------------------------+---------------------------+----------------------------+\n",
            "|                               3|                                3|                          3|                           3|\n",
            "|                               3|                                3|                          3|                           2|\n",
            "|                               3|                                3|                          3|                           3|\n",
            "|                               3|                                3|                          3|                           3|\n",
            "|                               3|                                3|                          3|                           3|\n",
            "+--------------------------------+---------------------------------+---------------------------+----------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_tbl.select(len_cols + [\"present_media_language\", \"label\"]).show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DspJCJWwQn5",
        "outputId": "64d08572-c316-4eec-9678-2241079b0bc0"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-----------+---------+----------------------+-----+\n",
            "|len_hashtags|len_domains|len_links|present_media_language|label|\n",
            "+------------+-----------+---------+----------------------+-----+\n",
            "|        0.94|        0.9|      0.6|                   221|    1|\n",
            "|        0.68|        0.6|      1.0|                   558|    0|\n",
            "|        0.38|        0.5|      0.3|                   471|    1|\n",
            "|        0.38|        0.3|      0.6|                   221|    1|\n",
            "|        0.86|        0.9|      1.0|                   402|    1|\n",
            "+------------+-----------+---------+----------------------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Wide & Deep Model Training"
      ],
      "metadata": {
        "id": "R3Aq5XkR9-tp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "from bigdl.orca.learn.tf2.estimator import Estimator"
      ],
      "metadata": {
        "id": "f77qR5q_wxAU"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wide_cols = ['engaged_with_user_is_verified', 'enaging_user_is_verified']\n",
        "wide_dims = [1, 1]\n",
        "cross_cols = ['present_media_language']\n",
        "cross_dims = [600]\n",
        "\n",
        "embedding_cols = []\n",
        "embedding_dims = []\n",
        "\n",
        "cat_cols = ['present_media',\n",
        "            'tweet_type',\n",
        "            'language']\n",
        "cat_dims = [12, 2, 66]\n",
        "count_cols = ['engaged_with_user_follower_count',\n",
        "              'engaged_with_user_following_count',\n",
        "              'enaging_user_follower_count',\n",
        "              'enaging_user_following_count']\n",
        "count_dims = [7, 7, 7, 7]\n",
        "indicator_cols = cat_cols + count_cols\n",
        "indicator_dims = cat_dims + count_dims\n",
        "\n",
        "continuous_cols = ['len_hashtags',\n",
        "                   'len_domains',\n",
        "                   'len_links']\n",
        "\n",
        "column_info = { \"wide_base_cols\": wide_cols,\n",
        "                \"wide_base_dims\": wide_dims,\n",
        "                \"wide_cross_cols\": cross_cols,\n",
        "                \"wide_cross_dims\": cross_dims,\n",
        "                \"indicator_cols\": indicator_cols,\n",
        "                \"indicator_dims\": indicator_dims,\n",
        "                \"continuous_cols\": continuous_cols,\n",
        "                \"embed_cols\": [],\n",
        "                \"embed_in_dims\": [],\n",
        "                \"embed_out_dims\": [],\n",
        "                \"label\": \"label\"}"
      ],
      "metadata": {
        "id": "qwJPSp5ByR8t"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(column_info, hidden_units=[100, 50, 25]):\n",
        "    \"\"\"Build an estimator appropriate for the given model type.\"\"\"\n",
        "    wide_base_input_layers = []\n",
        "    wide_base_layers = []\n",
        "    for i in range(len(column_info[\"wide_base_cols\"])):\n",
        "        wide_base_input_layers.append(tf.keras.layers.Input(shape=[], dtype=\"int32\"))\n",
        "        wide_base_layers.append(tf.keras.backend.one_hot(wide_base_input_layers[i], column_info[\"wide_base_dims\"][i] + 1))\n",
        "\n",
        "    wide_cross_input_layers = []\n",
        "    wide_cross_layers = []\n",
        "    for i in range(len(column_info[\"wide_cross_cols\"])):\n",
        "        wide_cross_input_layers.append(tf.keras.layers.Input(shape=[], dtype=\"int32\"))\n",
        "        wide_cross_layers.append(tf.keras.backend.one_hot(wide_cross_input_layers[i], column_info[\"wide_cross_dims\"][i]))\n",
        "\n",
        "    indicator_input_layers = []\n",
        "    indicator_layers = []\n",
        "    for i in range(len(column_info[\"indicator_cols\"])):\n",
        "        indicator_input_layers.append(tf.keras.layers.Input(shape=[], dtype=\"int32\"))\n",
        "        indicator_layers.append(tf.keras.backend.one_hot(indicator_input_layers[i], column_info[\"indicator_dims\"][i] + 1))\n",
        "\n",
        "    embed_input_layers = []\n",
        "    embed_layers = []\n",
        "    for i in range(len(column_info[\"embed_in_dims\"])):\n",
        "        embed_input_layers.append(tf.keras.layers.Input(shape=[], dtype=\"int32\"))\n",
        "        iembed = tf.keras.layers.Embedding(column_info[\"embed_in_dims\"][i] + 1,\n",
        "                                           output_dim=column_info[\"embed_out_dims\"][i])(embed_input_layers[i])\n",
        "        flat_embed = tf.keras.layers.Flatten()(iembed)\n",
        "        embed_layers.append(flat_embed)\n",
        "\n",
        "    continuous_input_layers = []\n",
        "    continuous_layers = []\n",
        "    for i in range(len(column_info[\"continuous_cols\"])):\n",
        "        continuous_input_layers.append(tf.keras.layers.Input(shape=[]))\n",
        "        continuous_layers.append(tf.keras.layers.Reshape(target_shape=(1,))(continuous_input_layers[i]))\n",
        "\n",
        "    if len(wide_base_layers + wide_cross_layers) > 1:\n",
        "        wide_input = tf.keras.layers.concatenate(wide_base_layers + wide_cross_layers, axis=1)\n",
        "    else:\n",
        "        wide_input = (wide_base_layers + wide_cross_layers)[0]\n",
        "    wide_out = tf.keras.layers.Dense(1)(wide_input)\n",
        "    if len(indicator_layers + embed_layers + continuous_layers) > 1:\n",
        "        deep_concat = tf.keras.layers.concatenate(indicator_layers +\n",
        "                                                  embed_layers +\n",
        "                                                  continuous_layers, axis=1)\n",
        "    else:\n",
        "        deep_concat = (indicator_layers + embed_layers + continuous_layers)[0]\n",
        "    linear = deep_concat\n",
        "    for ilayer in range(0, len(hidden_units)):\n",
        "        linear_mid = tf.keras.layers.Dense(hidden_units[ilayer])(linear)\n",
        "        bn = tf.keras.layers.BatchNormalization()(linear_mid)\n",
        "        relu = tf.keras.layers.ReLU()(bn)\n",
        "        dropout = tf.keras.layers.Dropout(0.1)(relu)\n",
        "        linear = dropout\n",
        "    deep_out = tf.keras.layers.Dense(1)(linear)\n",
        "    added = tf.keras.layers.add([wide_out, deep_out])\n",
        "    out = tf.keras.layers.Activation(\"sigmoid\")(added)\n",
        "    model = tf.keras.models.Model(wide_base_input_layers +\n",
        "                                  wide_cross_input_layers +\n",
        "                                  indicator_input_layers +\n",
        "                                  embed_input_layers +\n",
        "                                  continuous_input_layers,\n",
        "                                  out)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "sXH7Ys4ZyVY4"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\n",
        "    \"lr\": 0.0001,\n",
        "    \"column_info\": column_info,\n",
        "    \"inter_op_parallelism\": 4,\n",
        "    \"intra_op_parallelism\": 24\n",
        "}\n",
        "batch_size = 2560"
      ],
      "metadata": {
        "id": "lIzRRgGgymJP"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_creator(config):\n",
        "    model = build_model(column_info=config[\"column_info\"],\n",
        "                        hidden_units=[1024, 1024])\n",
        "    optimizer = tf.keras.optimizers.Adam(config[\"lr\"])\n",
        "    model.compile(optimizer=optimizer,\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['binary_accuracy', 'binary_crossentropy', 'AUC', 'Precision', 'Recall'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "JuhASNfdy0Op"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "estimator = Estimator.from_keras(\n",
        "    model_creator=model_creator,\n",
        "    verbose=True,\n",
        "    config=config,\n",
        "    workers_per_node=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W48FAO-Qy3w8",
        "outputId": "595f643a-654b-4f9f-f44a-6b6aa3942f51"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(Worker pid=479)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bigdl/orca/learn/tf2/tf_runner.py:318: _CollectiveAllReduceStrategyExperimental.__init__ (from tensorflow.python.distribute.collective_all_reduce_strategy) is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(Worker pid=479)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(Worker pid=479)\u001b[0m use distribute.MultiWorkerMirroredStrategy instead\n",
            "\u001b[2m\u001b[36m(Worker pid=478)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bigdl/orca/learn/tf2/tf_runner.py:318: _CollectiveAllReduceStrategyExperimental.__init__ (from tensorflow.python.distribute.collective_all_reduce_strategy) is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(Worker pid=478)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(Worker pid=478)\u001b[0m use distribute.MultiWorkerMirroredStrategy instead\n",
            "\u001b[2m\u001b[36m(Worker pid=479)\u001b[0m 2022-08-22 09:44:21.854823: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "\u001b[2m\u001b[36m(Worker pid=478)\u001b[0m 2022-08-22 09:44:21.855390: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "steps_per_epoch = math.ceil(train_size / batch_size)\n",
        "epochs = 5\n",
        "val_steps = math.ceil(valid_size / batch_size)\n",
        "\n",
        "callbacks = [EarlyStopping(monitor='val_auc', mode='max', verbose=1, patience=3)]"
      ],
      "metadata": {
        "id": "v7ANrx510Z3C"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def label_cols(column_info):\n",
        "    return [column_info[\"label\"]]\n",
        "\n",
        "def feature_cols(column_info):\n",
        "    return column_info[\"wide_base_cols\"] + column_info[\"wide_cross_cols\"] +\\\n",
        "                  column_info[\"indicator_cols\"] + column_info[\"embed_cols\"] + column_info[\"continuous_cols\"]\n",
        "\n",
        "estimator.fit(data=train_tbl.df,\n",
        "              epochs=epochs,\n",
        "              batch_size=batch_size,\n",
        "              steps_per_epoch=steps_per_epoch,\n",
        "              validation_data=valid_tbl.df,\n",
        "              validation_steps=val_steps,\n",
        "              callbacks=callbacks,\n",
        "              feature_cols=feature_cols(column_info),\n",
        "              label_cols=label_cols(column_info))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJV4ml1Vy_4D",
        "outputId": "db503122-1a2f-4690-a099-240b92a02c90"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(Worker pid=479)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bigdl/orca/learn/tf2/tf_runner.py:196: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(Worker pid=479)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(Worker pid=479)\u001b[0m rename to distribute_datasets_from_function\n",
            "\u001b[2m\u001b[36m(Worker pid=478)\u001b[0m WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bigdl/orca/learn/tf2/tf_runner.py:196: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "\u001b[2m\u001b[36m(Worker pid=478)\u001b[0m Instructions for updating:\n",
            "\u001b[2m\u001b[36m(Worker pid=478)\u001b[0m rename to distribute_datasets_from_function\n",
            "\u001b[2m\u001b[36m(Worker pid=479)\u001b[0m 2022-08-22 09:48:07.325853: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
            "\u001b[2m\u001b[36m(Worker pid=478)\u001b[0m 2022-08-22 09:48:07.325829: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(Worker pid=479)\u001b[0m Epoch 1/5\n",
            " 1/16 [>.............................] - ETA: 2:17 - loss: 0.9040 - binary_accuracy: 0.3836 - binary_crossentropy: 0.9040 - auc: 0.5017 - precision: 0.9340 - recall: 0.3626\n",
            " 2/16 [==>...........................] - ETA: 12s - loss: 0.8797 - binary_accuracy: 0.3885 - binary_crossentropy: 0.8797 - auc: 0.5188 - precision: 0.9381 - recall: 0.3685 \n",
            " 3/16 [====>.........................] - ETA: 11s - loss: 0.8671 - binary_accuracy: 0.3970 - binary_crossentropy: 0.8671 - auc: 0.4947 - precision: 0.9329 - recall: 0.3820\n",
            " 4/16 [======>.......................] - ETA: 10s - loss: 0.8516 - binary_accuracy: 0.4105 - binary_crossentropy: 0.8516 - auc: 0.4980 - precision: 0.9353 - recall: 0.3980\n",
            " 5/16 [========>.....................] - ETA: 9s - loss: 0.8356 - binary_accuracy: 0.4235 - binary_crossentropy: 0.8356 - auc: 0.5017 - precision: 0.9365 - recall: 0.4124 \n",
            " 6/16 [==========>...................] - ETA: 8s - loss: 0.8232 - binary_accuracy: 0.4337 - binary_crossentropy: 0.8232 - auc: 0.5024 - precision: 0.9365 - recall: 0.4244\n",
            " 7/16 [============>.................] - ETA: 7s - loss: 0.8097 - binary_accuracy: 0.4440 - binary_crossentropy: 0.8097 - auc: 0.4986 - precision: 0.9361 - recall: 0.4368\n",
            " 8/16 [==============>...............] - ETA: 6s - loss: 0.7980 - binary_accuracy: 0.4557 - binary_crossentropy: 0.7980 - auc: 0.4969 - precision: 0.9358 - recall: 0.4503\n",
            " 9/16 [===============>..............] - ETA: 5s - loss: 0.7867 - binary_accuracy: 0.4668 - binary_crossentropy: 0.7867 - auc: 0.4944 - precision: 0.9357 - recall: 0.4629\n",
            "10/16 [=================>............] - ETA: 5s - loss: 0.7734 - binary_accuracy: 0.4821 - binary_crossentropy: 0.7734 - auc: 0.5013 - precision: 0.9382 - recall: 0.4795\n",
            "11/16 [===================>..........] - ETA: 4s - loss: 0.7618 - binary_accuracy: 0.4962 - binary_crossentropy: 0.7618 - auc: 0.4998 - precision: 0.9376 - recall: 0.4955\n",
            "12/16 [=====================>........] - ETA: 3s - loss: 0.7504 - binary_accuracy: 0.5092 - binary_crossentropy: 0.7504 - auc: 0.5002 - precision: 0.9377 - recall: 0.5103\n",
            "13/16 [=======================>......] - ETA: 2s - loss: 0.7397 - binary_accuracy: 0.5221 - binary_crossentropy: 0.7397 - auc: 0.4968 - precision: 0.9368 - recall: 0.5255\n",
            "14/16 [=========================>....] - ETA: 1s - loss: 0.7290 - binary_accuracy: 0.5352 - binary_crossentropy: 0.7290 - auc: 0.4976 - precision: 0.9369 - recall: 0.5404\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.7184 - binary_accuracy: 0.5479 - binary_crossentropy: 0.7184 - auc: 0.4982 - precision: 0.9369 - recall: 0.5549\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.7083 - binary_accuracy: 0.5602 - binary_crossentropy: 0.7083 - auc: 0.4995 - precision: 0.9374 - recall: 0.5688\n",
            "16/16 [==============================] - 26s 1s/step - loss: 0.7083 - binary_accuracy: 0.5602 - binary_crossentropy: 0.7083 - auc: 0.4995 - precision: 0.9374 - recall: 0.5688 - val_loss: 0.6614 - val_binary_accuracy: 0.8167 - val_binary_crossentropy: 0.6614 - val_auc: 0.4822 - val_precision: 0.9321 - val_recall: 0.8667\n",
            "\u001b[2m\u001b[36m(Worker pid=479)\u001b[0m Epoch 2/5\n",
            " 1/16 [>.............................] - ETA: 12s - loss: 0.5297 - binary_accuracy: 0.7844 - binary_crossentropy: 0.5297 - auc: 0.5465 - precision: 0.9445 - recall: 0.8192\n",
            " 2/16 [==>...........................] - ETA: 11s - loss: 0.5255 - binary_accuracy: 0.7936 - binary_crossentropy: 0.5255 - auc: 0.5212 - precision: 0.9428 - recall: 0.8311\n",
            " 3/16 [====>.........................] - ETA: 10s - loss: 0.5174 - binary_accuracy: 0.8031 - binary_crossentropy: 0.5174 - auc: 0.5211 - precision: 0.9418 - recall: 0.8426\n",
            " 4/16 [======>.......................] - ETA: 10s - loss: 0.5130 - binary_accuracy: 0.8056 - binary_crossentropy: 0.5130 - auc: 0.5104 - precision: 0.9389 - recall: 0.8480\n",
            " 5/16 [========>.....................] - ETA: 9s - loss: 0.5080 - binary_accuracy: 0.8105 - binary_crossentropy: 0.5080 - auc: 0.5070 - precision: 0.9377 - recall: 0.8547 \n",
            " 6/16 [==========>...................] - ETA: 8s - loss: 0.5016 - binary_accuracy: 0.8173 - binary_crossentropy: 0.5016 - auc: 0.5003 - precision: 0.9370 - recall: 0.8631\n",
            " 7/16 [============>.................] - ETA: 7s - loss: 0.4955 - binary_accuracy: 0.8244 - binary_crossentropy: 0.4955 - auc: 0.5015 - precision: 0.9371 - recall: 0.8711\n",
            " 8/16 [==============>...............] - ETA: 6s - loss: 0.4882 - binary_accuracy: 0.8319 - binary_crossentropy: 0.4882 - auc: 0.5086 - precision: 0.9375 - recall: 0.8793\n",
            " 9/16 [===============>..............] - ETA: 5s - loss: 0.4826 - binary_accuracy: 0.8368 - binary_crossentropy: 0.4826 - auc: 0.5108 - precision: 0.9369 - recall: 0.8854\n",
            "10/16 [=================>............] - ETA: 5s - loss: 0.4760 - binary_accuracy: 0.8429 - binary_crossentropy: 0.4760 - auc: 0.5154 - precision: 0.9371 - recall: 0.8921\n",
            "11/16 [===================>..........] - ETA: 4s - loss: 0.4699 - binary_accuracy: 0.8491 - binary_crossentropy: 0.4699 - auc: 0.5162 - precision: 0.9374 - recall: 0.8990\n",
            "12/16 [=====================>........] - ETA: 3s - loss: 0.4638 - binary_accuracy: 0.8541 - binary_crossentropy: 0.4638 - auc: 0.5187 - precision: 0.9381 - recall: 0.9040\n",
            "13/16 [=======================>......] - ETA: 2s - loss: 0.4581 - binary_accuracy: 0.8586 - binary_crossentropy: 0.4581 - auc: 0.5181 - precision: 0.9383 - recall: 0.9090\n",
            "14/16 [=========================>....] - ETA: 1s - loss: 0.4527 - binary_accuracy: 0.8626 - binary_crossentropy: 0.4527 - auc: 0.5192 - precision: 0.9379 - recall: 0.9139\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.4473 - binary_accuracy: 0.8663 - binary_crossentropy: 0.4473 - auc: 0.5203 - precision: 0.9378 - recall: 0.9183\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.4425 - binary_accuracy: 0.8698 - binary_crossentropy: 0.4425 - auc: 0.5204 - precision: 0.9379 - recall: 0.9223\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(Worker pid=479)\u001b[0m 2022-08-22 09:48:47.417395: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
            "\u001b[2m\u001b[36m(Worker pid=478)\u001b[0m 2022-08-22 09:48:47.440609: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(Worker pid=479)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r16/16 [==============================] - 15s 950ms/step - loss: 0.4425 - binary_accuracy: 0.8698 - binary_crossentropy: 0.4425 - auc: 0.5204 - precision: 0.9379 - recall: 0.9223 - val_loss: 0.6346 - val_binary_accuracy: 0.9120 - val_binary_crossentropy: 0.6346 - val_auc: 0.4919 - val_precision: 0.9325 - val_recall: 0.9763\n",
            "\u001b[2m\u001b[36m(Worker pid=479)\u001b[0m Epoch 3/5\n",
            " 1/16 [>.............................] - ETA: 12s - loss: 0.3615 - binary_accuracy: 0.9238 - binary_crossentropy: 0.3615 - auc: 0.5022 - precision: 0.9370 - recall: 0.9850\n",
            " 2/16 [==>...........................] - ETA: 11s - loss: 0.3604 - binary_accuracy: 0.9221 - binary_crossentropy: 0.3604 - auc: 0.5078 - precision: 0.9352 - recall: 0.9850\n",
            " 3/16 [====>.........................] - ETA: 10s - loss: 0.3556 - binary_accuracy: 0.9240 - binary_crossentropy: 0.3556 - auc: 0.5137 - precision: 0.9363 - recall: 0.9858\n",
            " 4/16 [======>.......................] - ETA: 10s - loss: 0.3493 - binary_accuracy: 0.9272 - binary_crossentropy: 0.3493 - auc: 0.5175 - precision: 0.9382 - recall: 0.9875\n",
            " 5/16 [========>.....................] - ETA: 9s - loss: 0.3463 - binary_accuracy: 0.9281 - binary_crossentropy: 0.3463 - auc: 0.5210 - precision: 0.9381 - recall: 0.9887 \n",
            " 6/16 [==========>...................] - ETA: 8s - loss: 0.3437 - binary_accuracy: 0.9286 - binary_crossentropy: 0.3437 - auc: 0.5245 - precision: 0.9375 - recall: 0.9899\n",
            " 7/16 [============>.................] - ETA: 7s - loss: 0.3412 - binary_accuracy: 0.9299 - binary_crossentropy: 0.3412 - auc: 0.5201 - precision: 0.9378 - recall: 0.9910\n",
            " 8/16 [==============>...............] - ETA: 6s - loss: 0.3383 - binary_accuracy: 0.9308 - binary_crossentropy: 0.3383 - auc: 0.5208 - precision: 0.9381 - recall: 0.9916\n",
            " 9/16 [===============>..............] - ETA: 5s - loss: 0.3355 - binary_accuracy: 0.9310 - binary_crossentropy: 0.3355 - auc: 0.5231 - precision: 0.9380 - recall: 0.9920\n",
            "10/16 [=================>............] - ETA: 5s - loss: 0.3325 - binary_accuracy: 0.9314 - binary_crossentropy: 0.3325 - auc: 0.5273 - precision: 0.9380 - recall: 0.9925\n",
            "11/16 [===================>..........] - ETA: 4s - loss: 0.3295 - binary_accuracy: 0.9320 - binary_crossentropy: 0.3295 - auc: 0.5300 - precision: 0.9382 - recall: 0.9930\n",
            "12/16 [=====================>........] - ETA: 3s - loss: 0.3268 - binary_accuracy: 0.9326 - binary_crossentropy: 0.3268 - auc: 0.5314 - precision: 0.9383 - recall: 0.9934\n",
            "13/16 [=======================>......] - ETA: 2s - loss: 0.3235 - binary_accuracy: 0.9334 - binary_crossentropy: 0.3235 - auc: 0.5350 - precision: 0.9388 - recall: 0.9938\n",
            "14/16 [=========================>....] - ETA: 1s - loss: 0.3211 - binary_accuracy: 0.9337 - binary_crossentropy: 0.3211 - auc: 0.5375 - precision: 0.9389 - recall: 0.9940\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.3187 - binary_accuracy: 0.9340 - binary_crossentropy: 0.3187 - auc: 0.5392 - precision: 0.9390 - recall: 0.9943\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.3173 - binary_accuracy: 0.9337 - binary_crossentropy: 0.3173 - auc: 0.5409 - precision: 0.9384 - recall: 0.9946\n",
            "16/16 [==============================] - 15s 953ms/step - loss: 0.3173 - binary_accuracy: 0.9337 - binary_crossentropy: 0.3173 - auc: 0.5409 - precision: 0.9384 - recall: 0.9946 - val_loss: 0.6074 - val_binary_accuracy: 0.9312 - val_binary_crossentropy: 0.6074 - val_auc: 0.4984 - val_precision: 0.9331 - val_recall: 0.9979\n",
            "\u001b[2m\u001b[36m(Worker pid=479)\u001b[0m Epoch 4/5\n",
            " 1/16 [>.............................] - ETA: 12s - loss: 0.2964 - binary_accuracy: 0.9316 - binary_crossentropy: 0.2964 - auc: 0.5399 - precision: 0.9320 - recall: 0.9996\n",
            " 2/16 [==>...........................] - ETA: 12s - loss: 0.2920 - binary_accuracy: 0.9311 - binary_crossentropy: 0.2920 - auc: 0.5527 - precision: 0.9318 - recall: 0.9992\n",
            " 3/16 [====>.........................] - ETA: 11s - loss: 0.2894 - binary_accuracy: 0.9314 - binary_crossentropy: 0.2894 - auc: 0.5577 - precision: 0.9320 - recall: 0.9993\n",
            " 4/16 [======>.......................] - ETA: 10s - loss: 0.2831 - binary_accuracy: 0.9341 - binary_crossentropy: 0.2831 - auc: 0.5604 - precision: 0.9347 - recall: 0.9993\n",
            " 5/16 [========>.....................] - ETA: 9s - loss: 0.2816 - binary_accuracy: 0.9344 - binary_crossentropy: 0.2816 - auc: 0.5577 - precision: 0.9349 - recall: 0.9993 \n",
            " 6/16 [==========>...................] - ETA: 8s - loss: 0.2812 - binary_accuracy: 0.9340 - binary_crossentropy: 0.2812 - auc: 0.5616 - precision: 0.9345 - recall: 0.9994\n",
            " 7/16 [============>.................] - ETA: 7s - loss: 0.2770 - binary_accuracy: 0.9357 - binary_crossentropy: 0.2770 - auc: 0.5635 - precision: 0.9362 - recall: 0.9994\n",
            " 8/16 [==============>...............] - ETA: 6s - loss: 0.2738 - binary_accuracy: 0.9369 - binary_crossentropy: 0.2738 - auc: 0.5644 - precision: 0.9374 - recall: 0.9994\n",
            " 9/16 [===============>..............] - ETA: 5s - loss: 0.2717 - binary_accuracy: 0.9374 - binary_crossentropy: 0.2717 - auc: 0.5684 - precision: 0.9379 - recall: 0.9994\n",
            "10/16 [=================>............] - ETA: 5s - loss: 0.2704 - binary_accuracy: 0.9374 - binary_crossentropy: 0.2704 - auc: 0.5703 - precision: 0.9379 - recall: 0.9994\n",
            "11/16 [===================>..........] - ETA: 4s - loss: 0.2682 - binary_accuracy: 0.9382 - binary_crossentropy: 0.2682 - auc: 0.5710 - precision: 0.9386 - recall: 0.9995\n",
            "12/16 [=====================>........] - ETA: 3s - loss: 0.2681 - binary_accuracy: 0.9379 - binary_crossentropy: 0.2681 - auc: 0.5691 - precision: 0.9383 - recall: 0.9995\n",
            "13/16 [=======================>......] - ETA: 2s - loss: 0.2678 - binary_accuracy: 0.9377 - binary_crossentropy: 0.2678 - auc: 0.5688 - precision: 0.9381 - recall: 0.9996\n",
            "14/16 [=========================>....] - ETA: 1s - loss: 0.2668 - binary_accuracy: 0.9379 - binary_crossentropy: 0.2668 - auc: 0.5685 - precision: 0.9382 - recall: 0.9996\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.2665 - binary_accuracy: 0.9376 - binary_crossentropy: 0.2665 - auc: 0.5690 - precision: 0.9380 - recall: 0.9996\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2663 - binary_accuracy: 0.9374 - binary_crossentropy: 0.2663 - auc: 0.5675 - precision: 0.9377 - recall: 0.9996\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(Worker pid=479)\u001b[0m 2022-08-22 09:49:20.137071: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n",
            "\u001b[2m\u001b[36m(Worker pid=478)\u001b[0m 2022-08-22 09:49:20.151022: W tensorflow/core/framework/dataset.cc:768] Input of GeneratorDatasetOp::Dataset will not be optimized because the dataset does not implement the AsGraphDefInternal() method needed to apply optimizations.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(Worker pid=479)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r16/16 [==============================] - 19s 1s/step - loss: 0.2663 - binary_accuracy: 0.9374 - binary_crossentropy: 0.2663 - auc: 0.5675 - precision: 0.9377 - recall: 0.9996 - val_loss: 0.5814 - val_binary_accuracy: 0.9330 - val_binary_crossentropy: 0.5814 - val_auc: 0.4969 - val_precision: 0.9330 - val_recall: 1.0000\n",
            "\u001b[2m\u001b[36m(Worker pid=479)\u001b[0m Epoch 5/5\n",
            " 1/16 [>.............................] - ETA: 9s - loss: 0.2569 - binary_accuracy: 0.9332 - binary_crossentropy: 0.2569 - auc: 0.6120 - precision: 0.9336 - recall: 0.9996\n",
            " 2/16 [==>...........................] - ETA: 9s - loss: 0.2517 - binary_accuracy: 0.9363 - binary_crossentropy: 0.2517 - auc: 0.6062 - precision: 0.9365 - recall: 0.9998\n",
            " 3/16 [====>.........................] - ETA: 8s - loss: 0.2479 - binary_accuracy: 0.9387 - binary_crossentropy: 0.2479 - auc: 0.6009 - precision: 0.9388 - recall: 0.9999\n",
            " 4/16 [======>.......................] - ETA: 7s - loss: 0.2530 - binary_accuracy: 0.9357 - binary_crossentropy: 0.2530 - auc: 0.6014 - precision: 0.9358 - recall: 0.9999\n",
            " 5/16 [========>.....................] - ETA: 7s - loss: 0.2495 - binary_accuracy: 0.9377 - binary_crossentropy: 0.2495 - auc: 0.5942 - precision: 0.9378 - recall: 0.9999\n",
            " 6/16 [==========>...................] - ETA: 6s - loss: 0.2495 - binary_accuracy: 0.9378 - binary_crossentropy: 0.2495 - auc: 0.5896 - precision: 0.9378 - recall: 0.9999\n",
            " 7/16 [============>.................] - ETA: 5s - loss: 0.2491 - binary_accuracy: 0.9378 - binary_crossentropy: 0.2491 - auc: 0.5856 - precision: 0.9379 - recall: 0.9999\n",
            " 8/16 [==============>...............] - ETA: 5s - loss: 0.2500 - binary_accuracy: 0.9372 - binary_crossentropy: 0.2500 - auc: 0.5848 - precision: 0.9373 - recall: 0.9999\n",
            " 9/16 [===============>..............] - ETA: 4s - loss: 0.2493 - binary_accuracy: 0.9376 - binary_crossentropy: 0.2493 - auc: 0.5808 - precision: 0.9378 - recall: 0.9999\n",
            "10/16 [=================>............] - ETA: 3s - loss: 0.2490 - binary_accuracy: 0.9374 - binary_crossentropy: 0.2490 - auc: 0.5845 - precision: 0.9375 - recall: 0.9999\n",
            "11/16 [===================>..........] - ETA: 3s - loss: 0.2468 - binary_accuracy: 0.9382 - binary_crossentropy: 0.2468 - auc: 0.5865 - precision: 0.9384 - recall: 0.9998\n",
            "12/16 [=====================>........] - ETA: 2s - loss: 0.2463 - binary_accuracy: 0.9383 - binary_crossentropy: 0.2463 - auc: 0.5863 - precision: 0.9385 - recall: 0.9999\n",
            "13/16 [=======================>......] - ETA: 1s - loss: 0.2449 - binary_accuracy: 0.9387 - binary_crossentropy: 0.2449 - auc: 0.5874 - precision: 0.9388 - recall: 0.9999\n",
            "14/16 [=========================>....] - ETA: 1s - loss: 0.2434 - binary_accuracy: 0.9393 - binary_crossentropy: 0.2434 - auc: 0.5861 - precision: 0.9394 - recall: 0.9999\n",
            "15/16 [===========================>..] - ETA: 0s - loss: 0.2446 - binary_accuracy: 0.9385 - binary_crossentropy: 0.2446 - auc: 0.5874 - precision: 0.9386 - recall: 0.9999\n",
            "16/16 [==============================] - ETA: 0s - loss: 0.2438 - binary_accuracy: 0.9387 - binary_crossentropy: 0.2438 - auc: 0.5874 - precision: 0.9388 - recall: 0.9999\n",
            "16/16 [==============================] - 11s 686ms/step - loss: 0.2438 - binary_accuracy: 0.9387 - binary_crossentropy: 0.2438 - auc: 0.5874 - precision: 0.9388 - recall: 0.9999 - val_loss: 0.5580 - val_binary_accuracy: 0.9330 - val_binary_crossentropy: 0.5580 - val_auc: 0.5003 - val_precision: 0.9330 - val_recall: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'train_loss': 0.24382218718528748,\n",
              "  'train_binary_accuracy': 0.9387451410293579,\n",
              "  'train_binary_crossentropy': 0.24382218718528748,\n",
              "  'train_auc': 0.587367057800293,\n",
              "  'train_precision': 0.9388368129730225,\n",
              "  'train_recall': 0.9998959898948669,\n",
              "  'train_val_loss': 0.5580403208732605,\n",
              "  'train_val_binary_accuracy': 0.9330078363418579,\n",
              "  'train_val_binary_crossentropy': 0.5580403208732605,\n",
              "  'train_val_auc': 0.5002649426460266,\n",
              "  'train_val_precision': 0.9330078363418579,\n",
              "  'train_val_recall': 1.0}]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = estimator.get_model()\n",
        "tf.saved_model.save(model, \"recsys_wnd/\")\n",
        "\n",
        "stop_orca_context()"
      ],
      "metadata": {
        "id": "9vbE___M03UJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d33cca62-af3c-4b7a-dc7f-b181a9896ce0"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stopping orca context\n"
          ]
        }
      ]
    }
  ]
}