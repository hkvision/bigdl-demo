{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9f8562c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0882239",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/orca-demo/lib/python3.7/site-packages/pandas/util/_decorators.py:311: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  return func(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user  item  label\n",
       "0     1  1193      5\n",
       "1     1   661      3\n",
       "2     1   914      3\n",
       "3     1  3408      4\n",
       "4     1  2355      5"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data = read_csv(\"ml-1m/ratings.dat\", sep=\"::\", header=None, names=[\"user\", \"item\", \"label\"],\n",
    "                     usecols=[0, 1, 2], dtype={0: np.int32, 1: np.int32, 2: np.int32})\n",
    "full_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79c8ad07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 6040, 1, 3952)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_set = set(full_data[\"user\"].unique())\n",
    "item_set = set(full_data[\"item\"].unique())\n",
    "min_user_id = min(user_set)\n",
    "max_user_id = max(user_set)\n",
    "min_item_id = min(item_set)\n",
    "max_item_id = max(item_set)\n",
    "\n",
    "min_user_id, max_user_id, min_item_id, max_item_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d76dc746",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(full_data, test_size=0.2, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f123aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /root/anaconda3/envs/orca-demo/lib/python3.7/site-packages/tensorflow_core/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /root/anaconda3/envs/orca-demo/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1, 10)        60410       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 1, 10)        39530       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 10)           0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 10)           0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 20)           0           flatten[0][0]                    \n",
      "                                                                 flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 1, 20)        120820      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 1, 20)        79060       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 20)           420         concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 20)           0           embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 20)           0           embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10)           210         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (None, 20)           0           flatten_2[0][0]                  \n",
      "                                                                 flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 30)           0           dense_1[0][0]                    \n",
      "                                                                 multiply[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            31          concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 300,481\n",
      "Trainable params: 300,481\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "num_users = max_user_id + 1\n",
    "num_items = max_item_id + 1\n",
    "\n",
    "user_input = tf.keras.layers.Input(shape=(1,), dtype=\"int32\")\n",
    "item_input = tf.keras.layers.Input(shape=(1,), dtype=\"int32\")\n",
    "\n",
    "# Multi-layer Perceptron\n",
    "mlp_embed_user = tf.keras.layers.Embedding(input_dim=num_users,\n",
    "                                           output_dim=10,\n",
    "                                           input_length=1)(user_input)\n",
    "mlp_embed_item = tf.keras.layers.Embedding(input_dim=num_items,\n",
    "                                           output_dim=10,\n",
    "                                           input_length=1)(item_input)\n",
    "user_latent = tf.keras.layers.Flatten()(mlp_embed_user)\n",
    "item_latent = tf.keras.layers.Flatten()(mlp_embed_item)\n",
    "\n",
    "mlp_latent = tf.keras.layers.concatenate([user_latent, item_latent], axis=1)\n",
    "mlp_latent = tf.keras.layers.Dense(20, activation=\"relu\")(mlp_latent)\n",
    "mlp_latent = tf.keras.layers.Dense(10, activation=\"relu\")(mlp_latent)\n",
    "\n",
    "# Matrix Factorization\n",
    "mf_embed_user = tf.keras.layers.Embedding(input_dim=num_users,\n",
    "                                          output_dim=20,\n",
    "                                          input_length=1)(user_input)\n",
    "mf_embed_item = tf.keras.layers.Embedding(input_dim=num_items,\n",
    "                                          output_dim=20,\n",
    "                                          input_length=1)(item_input)\n",
    "mf_user_flatten = tf.keras.layers.Flatten()(mf_embed_user)\n",
    "mf_item_flatten = tf.keras.layers.Flatten()(mf_embed_item)\n",
    "\n",
    "mf_latent = tf.keras.layers.multiply([mf_user_flatten, mf_item_flatten])\n",
    "concated_model = tf.keras.layers.concatenate([mlp_latent, mf_latent], axis=1)\n",
    "prediction = tf.keras.layers.Dense(1, activation=\"relu\")(concated_model)\n",
    "\n",
    "model = tf.keras.Model([user_input, item_input], prediction)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ac3d3fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800167 samples, validate on 200042 samples\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-06 09:44:25.450611: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-05-06 09:44:25.450642: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-05-06 09:44:25.450661: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (aep-001): /proc/driver/nvidia/version does not exist\n",
      "2022-05-06 09:44:25.451219: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\n",
      "2022-05-06 09:44:25.460716: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2700000000 Hz\n",
      "2022-05-06 09:44:25.466514: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55aaf0d0b970 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-05-06 09:44:25.466541: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800167/800167 [==============================] - 5s 7us/sample - loss: 1.0466 - val_loss: 0.7955\n",
      "Epoch 2/2\n",
      "800167/800167 [==============================] - 5s 6us/sample - loss: 0.7318 - val_loss: 0.7690\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff90dda44d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(1e-2)\n",
    "model.compile(optimizer=optimizer, loss=\"mean_squared_error\")\n",
    "model.fit([train.user, train.item], train.label,\n",
    "          batch_size=800,\n",
    "          epochs=2,\n",
    "          validation_data=([test.user, test.item], test.label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91b2e435",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-06 09:44:36.589221: W tensorflow/python/util/util.cc:299] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(model, \"./model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
